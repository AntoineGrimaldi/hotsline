{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c03ebe-5caa-48b0-993e-915f8ba08a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tonic version installed -> 1.0.19\n",
      "Number of GPU devices available: 1\n",
      "GPU 1 named GeForce RTX 2080 Ti\n",
      "number of samples in the training set: 60000\n",
      "number of samples in the testing set: 10000\n",
      "device -> cuda\n",
      "device -> cuda\n"
     ]
    }
   ],
   "source": [
    "import tonic, torch, os\n",
    "from hots.network import network\n",
    "from hots.utils import apply_jitter, get_loader, make_histogram_classification, HOTS_Dataset, fit_mlr, predict_mlr, score_classif_events\n",
    "import numpy as np\n",
    "\n",
    "print(f'Tonic version installed -> {tonic.__version__}')\n",
    "\n",
    "print(f'Number of GPU devices available: {torch.cuda.device_count()}')\n",
    "for N_gpu in range(torch.cuda.device_count()):\n",
    "    print(f'GPU {N_gpu+1} named {torch.cuda.get_device_name(N_gpu)}')\n",
    "    \n",
    "    \n",
    "kfold = None\n",
    "\n",
    "type_transform = tonic.transforms.NumpyAsType(int)\n",
    "trainset = tonic.datasets.NMNIST(save_to='../../Data/', train=True, transform=type_transform)\n",
    "testset = tonic.datasets.NMNIST(save_to='../../Data/', train=False, transform=type_transform)\n",
    "loader = get_loader(trainset, kfold=300)\n",
    "trainloader = get_loader(trainset, kfold=kfold)\n",
    "testloader = get_loader(testset, kfold=kfold)\n",
    "num_sample_train = len(trainloader)\n",
    "num_sample_test = len(testloader)\n",
    "n_classes = len(testset.classes)\n",
    "print(f'number of samples in the training set: {len(trainloader)}')\n",
    "print(f'number of samples in the testing set: {len(testloader)}')\n",
    "\n",
    "\n",
    "name = 'homeohots'\n",
    "homeo = True\n",
    "timestr = '2022-04-22'\n",
    "dataset_name = 'nmnist'\n",
    "\n",
    "Rz = [2, 4]\n",
    "N_neuronz = [16, 32]\n",
    "tauz = [1e4*2, 1e4*16]\n",
    "\n",
    "hots = network(name, dataset_name, timestr, trainset.sensor_size, nb_neurons = N_neuronz, tau = tauz, R = Rz, homeo = homeo)\n",
    "\n",
    "initial_name = hots.name\n",
    "\n",
    "name_nohomeo = 'hots'\n",
    "hots_nohomeo = network(name, dataset_name, timestr, trainset.sensor_size, nb_neurons = N_neuronz, tau = tauz, R = Rz, homeo = False)\n",
    "\n",
    "initial_name_nohomeo = hots_nohomeo.name\n",
    "\n",
    "\n",
    "filtering_threshold = [2*Rz[L] for L in range(len(Rz))]\n",
    "if not os.path.exists('../Records/'):\n",
    "    os.mkdir('../Records/')\n",
    "    os.mkdir('../Records/networks/')\n",
    "path = '../Records/networks/'+hots.name+'.pkl'\n",
    "if not os.path.exists(path):\n",
    "    hots.clustering(loader, trainset.ordering, filtering_threshold = filtering_threshold)\n",
    "path_nohomeo = '../Records/networks/'+hots_nohomeo.name+'.pkl'\n",
    "if not os.path.exists(path_nohomeo):\n",
    "    hots_nohomeo.clustering(loader, trainset.ordering, filtering_threshold = filtering_threshold)\n",
    "    \n",
    "    \n",
    "jitter = (None, None)\n",
    "num_workers = 0\n",
    "learning_rate = 0.005\n",
    "beta1, beta2 = 0.9, 0.999\n",
    "betas = (beta1, beta2)\n",
    "num_epochs = 2 ** 5 + 1\n",
    "N_output_neurons = N_neuronz[-1]\n",
    "ts_size = (trainset.sensor_size[0],trainset.sensor_size[1],N_output_neurons)\n",
    "tau_cla = 1e5\n",
    "\n",
    "train_path = f'../Records/output/train/{hots.name}_{num_sample_train}_{jitter}/'\n",
    "test_path = f'../Records/output/test/{hots.name}_{num_sample_test}_{jitter}/'\n",
    "model_path = f'../Records/networks/{hots.name}_{tau_cla}_{learning_rate}_{betas}_{num_epochs}_{jitter}.pkl'\n",
    "results_path = f'../Records/LR_results/{hots.name}_{tau_cla}_{learning_rate}_{betas}_{num_epochs}_{jitter}.pkl'\n",
    "\n",
    "hots.coding(trainloader, trainset.ordering, trainset.classes, training=True, verbose=False)\n",
    "hots.coding(testloader, trainset.ordering, trainset.classes, training=False, verbose=False)\n",
    "\n",
    "trainset_output = HOTS_Dataset(train_path, trainset.sensor_size, dtype=trainset.dtype, transform=type_transform)\n",
    "trainoutputloader = get_loader(trainset_output)\n",
    "testset_output = HOTS_Dataset(test_path, trainset.sensor_size, dtype=trainset.dtype, transform=type_transform)\n",
    "testoutputloader = get_loader(testset_output)\n",
    "\n",
    "classif_layer, losses = fit_mlr(trainoutputloader, model_path, tau_cla, learning_rate, betas, num_epochs, ts_size, trainset.ordering, len(trainset.classes))\n",
    "\n",
    "hots_nohomeo.coding(trainloader, trainset.ordering, trainset.classes, training=True, verbose=False)\n",
    "\n",
    "train_path_nohomeo = f'../Records/output/train/{hots_nohomeo.name}_{num_sample_train}_{jitter}/'\n",
    "model_path_nohomeo = f'../Records/networks/{hots_nohomeo.name}_{tau_cla}_{learning_rate}_{betas}_{num_epochs}_{jitter}.pkl'\n",
    "test_path_nohomeo = f'../Records/output/test/{hots_nohomeo.name}_{num_sample_test}_{jitter}/'\n",
    "\n",
    "trainset_output_nohomeo = HOTS_Dataset(train_path_nohomeo, trainset.sensor_size, dtype=trainset.dtype, transform=type_transform)\n",
    "\n",
    "hots_nohomeo.coding(testloader, testset.ordering, testset.classes, training=False, jitter=jitter, verbose=False)\n",
    "testset_output_nohomeo = HOTS_Dataset(test_path_nohomeo, trainset.sensor_size, dtype=trainset.dtype, transform=type_transform)\n",
    "\n",
    "likelihood, true_target, timestamps = predict_mlr(classif_layer,tau_cla,testoutputloader,results_path,ts_size,testset_output.ordering)\n",
    "score = make_histogram_classification(trainset_output, testset_output, N_neuronz[-1])\n",
    "score_nohomeo = make_histogram_classification(trainset_output_nohomeo, testset_output_nohomeo, N_neuronz[-1])\n",
    "meanac, onlinac, lastac = score_classif_events(likelihood, true_target, n_classes, original_accuracy = score, original_accuracy_nohomeo = score_nohomeo, figure_name = 'nmnist_online.pdf')\n",
    "print(f'last accuracy: {lastac*100}%')\n",
    "\n",
    "kfold = 10\n",
    "\n",
    "standard_spatial_jitter_min = 0\n",
    "standard_spatial_jitter_max = 10\n",
    "apply_jitter(standard_spatial_jitter_min, standard_spatial_jitter_max, 'spatial', num_sample_test//kfold, n_classes, hots, hots_nohomeo, classif_layer, tau_cla, dataset_name, trainset_output, trainset_output_nohomeo, learning_rate ,betas ,num_epochs, kfold = kfold);\n",
    "\n",
    "\n",
    "standard_temporal_jitter_min = 3\n",
    "standard_temporal_jitter_max = 7\n",
    "apply_jitter(standard_temporal_jitter_min, standard_temporal_jitter_max, 'temporal', num_sample_test//kfold, n_classes, hots,hots_nohomeo, classif_layer, tau_cla, dataset_name, trainset_output, trainset_output_nohomeo, learning_rate ,betas ,num_epochs,  kfold = kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f53aa13-17fb-4a3c-bcd4-1e0b3b17e93a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa582021-e186-40f7-a0b3-6c28371f785c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
