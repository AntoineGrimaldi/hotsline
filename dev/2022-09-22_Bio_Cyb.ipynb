{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20b95700-514a-4191-9a3a-e93f51ca4460",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc71e20e-fe4f-4650-b7f8-307665ffc42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/antoine/homhots/hotsline/hots\n",
      "Tonic version installed -> 1.2.1\n",
      "Number of GPU devices available: 1\n",
      "GPU 1 named GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "%cd ../hots\n",
    "import tonic, torch, os, pickle, sys\n",
    "from tqdm import tqdm\n",
    "from network import network\n",
    "from layer import mlrlayer\n",
    "from timesurface import timesurface\n",
    "from utils import apply_jitter, get_loader, get_sliced_loader, make_histogram_classification, HOTS_Dataset, fit_mlr, predict_mlr, score_classif_events, plotjitter, printfig\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(f'Tonic version installed -> {tonic.__version__}')\n",
    "\n",
    "print(f'Number of GPU devices available: {torch.cuda.device_count()}')\n",
    "for N_gpu in range(torch.cuda.device_count()):\n",
    "    print(f'GPU {N_gpu+1} named {torch.cuda.get_device_name(N_gpu)}')\n",
    "    \n",
    "import zipfile as z\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "\n",
    "\n",
    "class DVSGesture_dataset(VisionDataset):\n",
    "    \"\"\"DVSGesture <http://research.ibm.com/dvsgesture/> dataset, either reduced or foveated.\n",
    "    arguments:\n",
    "        repertory: root repertory where the different processed datasets are stored \n",
    "        type_data: must be either test (to load test data), reduce (to load reduced data) or fovea (to load foveated data)\n",
    "        spatial_divider: spatial dividing factor (all data is divided by 4, no need to change default)\n",
    "        structural_divider: structural dividing factor, to keep only a certain percentage of the processed data \n",
    "                    (if want to charge the whole processed data, set structural_divider to 100)\n",
    "        method: spacial downscaling method \n",
    "                    (if type_data not 'test', roi_method must be either 'funnelling', 'eventcount', 'linear' or 'cubic')\n",
    "        roi_method: ROI data to use during foveation \n",
    "                    if type_data is 'fovea' and roi is maintained to default None, then use data foveated on whole input data ; \n",
    "                    else, use data foveated on downscaled data using a certain method)\n",
    "    \"\"\"\n",
    "\n",
    "    classes = [\n",
    "        \"hand_clapping\",\n",
    "        \"right_hand_wave\",\n",
    "        \"left_hand_wave\",\n",
    "        \"right_arm_clockwise\",\n",
    "        \"right_arm_counter_clockwise\",\n",
    "        \"left_arm_clockwise\",\n",
    "        \"left_arm_counter_clockwise\",\n",
    "        \"arm_roll\",\n",
    "        \"air_drums\",\n",
    "        \"air_guitar\",\n",
    "        \"other_gestures\",\n",
    "    ]\n",
    "\n",
    "    sensor_size = (128, 128)\n",
    "    ordering = \"xypt\"\n",
    "    dtype = np.dtype([(\"x\", np.int16), (\"y\", np.int16), (\"p\", bool), (\"t\", np.int64)])\n",
    "\n",
    "    def __init__(\n",
    "        self, repertory, type_data, spatial_divider=4, structural_divider=100, method=None, roi_method=None, \n",
    "    transform = tonic.transforms.NumpyAsType(int)):\n",
    "        super(DVSGesture_dataset, self).__init__(repertory)\n",
    "        assert type_data in ['test', 'reduce', 'fovea'], \"Wrong 'type_data' argument\"\n",
    "\n",
    "        if type_data == 'test':\n",
    "            self.zip_name = type_data\n",
    "            self.folder_name = 'Test data/'\n",
    "        \n",
    "        elif type_data == 'reduce':\n",
    "            assert method in ['funnelling', 'eventcount', 'linear', 'cubic'], \"Wrong 'method' argument\"\n",
    "            self.zip_name = 'reduced_data_'+method+'_div'+str(spatial_divider)\n",
    "            self.folder_name = 'Reduced data/Method - '+method+'/'\n",
    "        \n",
    "        else : \n",
    "            assert method in ['funnelling', 'eventcount', 'linear', 'cubic'], \"Wrong 'method' argument\"\n",
    "            assert roi_method in ['funnelling', 'eventcount', 'linear', 'cubic', None], \"Wrong 'roi_method' argument\"\n",
    "            \n",
    "            if roi_method == None:\n",
    "                roi_method = 'no reduc'\n",
    "            self.folder_name = 'Foveated data/ROI data - '+roi_method+'/Method - '+method+'/'\n",
    "            \n",
    "            if roi_method == 'no reduc':\n",
    "                roi_method = 'none'\n",
    "            self.zip_name = 'foveated_data_'+method+'_div'+str(spatial_divider)+'_ROI'+roi_method\n",
    "\n",
    "        if structural_divider != 100:\n",
    "            assert structural_divider in [5,10,20,40,60,80], \"Wrong 'structural_divider' argument\"\n",
    "            self.zip_name += '_'+str(structural_divider)+'%'\n",
    "\n",
    "        self.location_on_system = repertory\n",
    "        self.data = []\n",
    "        self.samples = []\n",
    "        self.targets = []\n",
    "        #self.transform = transform\n",
    "\n",
    "        file_path = os.path.join(self.location_on_system, self.folder_name, self.zip_name)\n",
    "        \n",
    "        if not os.path.exists(file_path) and os.path.exists(file_path+'.zip'):\n",
    "            \n",
    "            print('Extracting into '+file_path+'...')\n",
    "            with z.ZipFile(file_path+'.zip', 'r') as zip_dir :\n",
    "                zip_dir.extractall(os.path.join(self.location_on_system, self.folder_name))\n",
    "            print('Extraction done')\n",
    "\n",
    "        if os.path.exists(file_path):\n",
    "    \n",
    "            for path, dirs, files in os.walk(file_path):\n",
    "                dirs.sort()\n",
    "                for file in files:\n",
    "                    if file.endswith(\"npy\"):\n",
    "                        self.samples.append(path + \"/\" + file)\n",
    "                        self.targets.append(int(file[:-4]))\n",
    "\n",
    "        else: \n",
    "            print('Error: The folder '+file_path+' does not exist')\n",
    "            sys.exit()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        events = np.load(self.samples[index])\n",
    "        events[:, 3] *= 1000  # convert from ms to us\n",
    "        target = self.targets[index]\n",
    "        events = np.lib.recfunctions.unstructured_to_structured(events, self.dtype)\n",
    "        if self.transform is not None:\n",
    "            events = self.transform(events, self.sensor_size, self.ordering)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return events, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ce4a781-39a3-4427-aa25-f31ee9f43c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py   \u001b[0m\u001b[01;34m__pycache__\u001b[0m/  layer.pyc   timesurface.py\n",
      "__init__.pyc  layer.py      network.py  utils.py\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e345d67e-a539-46af-9c0b-a0de3a0b4a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reduced data/Method - cubic/'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2f706ec-7788-4f03-9835-ed263d6786b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tonic.datasets' has no attribute 'PokerDVS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtonic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SlicedDataset\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtonic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mslicers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SliceByTime\n\u001b[0;32m----> 4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtonic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPokerDVS\u001b[49m(save_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../Data\u001b[39m\u001b[38;5;124m\"\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m slicing_time_window \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m  \u001b[38;5;66;03m# microseconds\u001b[39;00m\n\u001b[1;32m      7\u001b[0m slicer \u001b[38;5;241m=\u001b[39m SliceByTime(time_window\u001b[38;5;241m=\u001b[39mslicing_time_window)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tonic.datasets' has no attribute 'PokerDVS'"
     ]
    }
   ],
   "source": [
    "from tonic import SlicedDataset\n",
    "from tonic.slicers import SliceByTime\n",
    "\n",
    "dataset = tonic.datasets.NMNIST(save_to=\"../../Data\", train=False)\n",
    "\n",
    "slicing_time_window = 1000  # microseconds\n",
    "slicer = SliceByTime(time_window=slicing_time_window)\n",
    "sliced_dataset = SlicedDataset(\n",
    "    dataset, slicer=slicer, metadata_path=\"./metadata/nmnist\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae36c427-4052-4932-b642-352b87f5af45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata written to ../../Data/DVSGesture_reduced/Reduced data/Method - cubic/metadata/slice_metadata.h5.\n"
     ]
    }
   ],
   "source": [
    "kfold_test = None\n",
    "kfold_clust = 10\n",
    "ts_batch_size = 1000\n",
    "\n",
    "dataset_name = 'gesture'\n",
    "slicing_time_window = 1e6\n",
    "\n",
    "type_transform = tonic.transforms.NumpyAsType(int)\n",
    "#trainset = tonic.datasets.DVSGesture(save_to='../../Data/', train=True, transform=type_transform)\n",
    "\n",
    "repertory = '../../Data/DVSGesture_reduced'\n",
    "type_data = 'reduce'\n",
    "method = 'cubic'\n",
    "roi_method = None\n",
    "shuffle = False\n",
    "num_workers = 0\n",
    "\n",
    "testset = DVSGesture_dataset(repertory, type_data, spatial_divider=4, structural_divider=100, method=method, roi_method=roi_method)\n",
    "\n",
    "metadata_path = testset.location_on_system+'/'+testset.folder_name+'metadata'\n",
    "slicer = tonic.slicers.SliceAtTimePoints(start_tw = [0], end_tw = [slicing_time_window])\n",
    "sliced_dataset = tonic.SlicedDataset(testset, slicer = slicer, transform = type_transform, metadata_path = metadata_path)\n",
    "loader = torch.utils.data.DataLoader(sliced_dataset, shuffle=shuffle, num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "363e9cd7-68cc-4a7c-b45d-72bd702a60f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "events, target = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "115bf04c-ec3a-41e7-bb2c-e39e5e466282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[      2,      98,       1, 4952831],\n",
      "         [      0,      97,       1, 4952831],\n",
      "         [      0,      96,       1, 4952831],\n",
      "         ...,\n",
      "         [     37,     106,       1,  998590],\n",
      "         [     37,     107,       1,  998590],\n",
      "         [     36,     106,       1,  998590]]])\n"
     ]
    }
   ],
   "source": [
    "print(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eb7981-fd14-4fd9-a233-c8018bb0fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
