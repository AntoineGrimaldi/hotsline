{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1323e1fd-cd1d-4b6f-8de6-0a71f2d7a0b8",
   "metadata": {},
   "source": [
    "# [hotsline](https://github.com/AntoineGrimaldi/hotsline) algorithm to replicate results from [this paper](https://www.techrxiv.org/articles/preprint/A_robust_event-driven_approach_to_always-on_object_recognition/18003077/1)\n",
    "## Load events of the POKER_DVS dataset with [Tonic](https://tonic.readthedocs.io/en/latest/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41e167bc-5794-4989-8b83-eb671436db30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/antoine/homhots/hotsline/hots\n",
      " Tonic version installed -> 1.0.15\n",
      "number of samples in the dataset: 48\n"
     ]
    }
   ],
   "source": [
    "import tonic, torch\n",
    "%cd ../hots\n",
    "from utils import get_loader, get_dataset_info\n",
    "from network import network\n",
    "from timesurface import timesurface\n",
    "\n",
    "print(f' Tonic version installed -> {tonic.__version__}')\n",
    "\n",
    "transform = tonic.transforms.NumpyAsType(int)\n",
    "dataset = tonic.datasets.POKERDVS(save_to='../../Data/', train=True, transform=transform)\n",
    "loader = get_loader(dataset)\n",
    "#get_dataset_info(dataset, properties = ['time', 'mean_isi', 'nb_events']);\n",
    "print(f'number of samples in the dataset: {len(loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3003c09-348b-4e6b-ad09-e3999f7f4839",
   "metadata": {},
   "source": [
    "## Parameter tuning\n",
    "### Choice of a time constant for time surfaces sent as input of the network\n",
    "Tau for the first layer is chosen empirically by measuring the entropy of the time surfaces sent as input of the network. For different tau, we measure the entropy of the time surfaces of the dataset and choose the given tau that maximizes this entropy value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf690da-e4ab-4d23-b741-cbf1f7fefd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████         | 45/48 [03:03<00:13,  4.39s/it]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "time_surface_size = (17,17)\n",
    "tauz = np.arange(1,20)*1e3\n",
    "entropy = []\n",
    "\n",
    "loader = get_loader(dataset)\n",
    "for events, target in tqdm(loader):\n",
    "    for tau in tauz:\n",
    "        TSs, indices = timesurface(events.squeeze(), dataset.sensor_size, dataset.ordering, tau = tau,  surface_dimensions=time_surface_size)\n",
    "        entropy.append(-(TSs*torch.log(TSs)).mean(dim=(1,2,3)).nanmean().detach().cpu())\n",
    "    #plt.plot(tauz, entropy[-len(tauz):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5374189b-9496-4873-89c1-afc00c18a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ent = []\n",
    "std_ent = []\n",
    "for ind, tau in enumerate(tauz):\n",
    "    entropy_tau = entropy[ind::48]\n",
    "    mean_ent.append(np.nanmean(entropy_tau))\n",
    "    std_ent.append(np.nanstd(entropy_tau))\n",
    "    \n",
    "plt.plot(tauz,mean_ent)\n",
    "plt.fill_between(tauz, np.array(mean_ent)-np.array(std_ent), np.array(mean_ent)+np.array(std_ent), alpha = 0.5)\n",
    "\n",
    "index = np.argmax(np.array(mean_ent)**2/np.array(std_ent))\n",
    "print(f'Optimal tau: {tauz[index]*1e-3} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3ea28e-0d10-4170-bfdc-54bad8694a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "time_surface_size = (5,5)\n",
    "tauz = np.arange(1,20)*1e3\n",
    "entropy = []\n",
    "\n",
    "loader = get_loader(dataset)\n",
    "for events, target in tqdm(loader):\n",
    "    for tau in tauz:\n",
    "        TSs, indices = timesurface(events.squeeze(), dataset.sensor_size, dataset.ordering, tau = tau,  surface_dimensions=time_surface_size)\n",
    "        entropy.append(-(TSs*torch.log(TSs)).mean(dim=(1,2,3)).nanmean().detach().cpu())\n",
    "mean_ent = []\n",
    "std_ent = []\n",
    "for ind, tau in enumerate(tauz):\n",
    "    entropy_tau = entropy[ind::48]\n",
    "    mean_ent.append(np.nanmean(entropy_tau))\n",
    "    std_ent.append(np.nanstd(entropy_tau))\n",
    "    \n",
    "plt.plot(tauz,mean_ent)\n",
    "plt.fill_between(tauz, np.array(mean_ent)-np.array(std_ent), np.array(mean_ent)+np.array(std_ent), alpha = 0.5)\n",
    "\n",
    "index = np.argmax(np.array(mean_ent)**2/np.array(std_ent))\n",
    "print(f'Optimal tau: {tauz[index]*1e-3} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e365c92-f9ed-402c-b98e-8d890bff32ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "time_surface_size = (9,9)\n",
    "tauz = np.arange(1,20)*1e3\n",
    "entropy = []\n",
    "\n",
    "loader = get_loader(dataset)\n",
    "for events, target in tqdm(loader):\n",
    "    for tau in tauz:\n",
    "        TSs, indices = timesurface(events.squeeze(), dataset.sensor_size, dataset.ordering, tau = tau,  surface_dimensions=time_surface_size)\n",
    "        entropy.append(-(TSs*torch.log(TSs)).mean(dim=(1,2,3)).nanmean().detach().cpu())\n",
    "mean_ent = []\n",
    "std_ent = []\n",
    "for ind, tau in enumerate(tauz):\n",
    "    entropy_tau = entropy[ind::48]\n",
    "    mean_ent.append(np.nanmean(entropy_tau))\n",
    "    std_ent.append(np.nanstd(entropy_tau))\n",
    "    \n",
    "plt.plot(tauz,mean_ent)\n",
    "plt.fill_between(tauz, np.array(mean_ent)-np.array(std_ent), np.array(mean_ent)+np.array(std_ent), alpha = 0.5)\n",
    "\n",
    "index = np.argmax(np.array(mean_ent)**2/np.array(std_ent))\n",
    "print(f'Optimal tau: {tauz[index]*1e-3} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb8b7a1-fd73-4e83-8180-2beac936800c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
