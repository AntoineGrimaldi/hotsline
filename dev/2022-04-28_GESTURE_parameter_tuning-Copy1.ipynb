{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1323e1fd-cd1d-4b6f-8de6-0a71f2d7a0b8",
   "metadata": {},
   "source": [
    "# [hotsline](https://github.com/AntoineGrimaldi/hotsline) algorithm to replicate results from [this paper](https://www.techrxiv.org/articles/preprint/A_robust_event-driven_approach_to_always-on_object_recognition/18003077/1)\n",
    "## Load events of the NMNIST dataset with [Tonic](https://tonic.readthedocs.io/en/latest/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a757b26-fb4f-4947-a7ff-1751a686aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41e167bc-5794-4989-8b83-eb671436db30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/antoine/homhots/hotsline/hots\n",
      "Tonic version installed -> 1.0.19\n",
      "Number of GPU devices available: 1\n",
      "GPU 1 named GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "%cd ../hots\n",
    "import tonic, torch, os, pickle\n",
    "from tqdm import tqdm\n",
    "from network import network\n",
    "from layer import mlrlayer\n",
    "from timesurface import timesurface\n",
    "from utils import apply_jitter, get_loader, get_sliced_loader, make_histogram_classification, HOTS_Dataset, fit_mlr, predict_mlr, score_classif_events, plotjitter, printfig, online_accuracy, make_and_display_ts\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(f'Tonic version installed -> {tonic.__version__}')\n",
    "\n",
    "print(f'Number of GPU devices available: {torch.cuda.device_count()}')\n",
    "for N_gpu in range(torch.cuda.device_count()):\n",
    "    print(f'GPU {N_gpu+1} named {torch.cuda.get_device_name(N_gpu)}')\n",
    "    \n",
    "#record_path = '/envau/work/neopto/USERS/GRIMALDI/HOTS/hotsline/Records/'\n",
    "record_path = '../Records/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91caa80b-9124-4c79-80f9-e6fad8ef1964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Data/DVSGesture/metadata/gesture_1000_True_True\n",
      "Read metadata from disk.\n",
      "../../Data/DVSGesture/metadata/gesture_1000_True_True\n",
      "Read metadata from disk.\n",
      "../../Data/DVSGesture/metadata/gesture_1000_True_False\n",
      "Read metadata from disk.\n",
      "number of samples in the training set: 209\n",
      "number of samples in the testing set: 44\n"
     ]
    }
   ],
   "source": [
    "kfold_test = 5\n",
    "kfold_clust = 10\n",
    "ts_batch_size = int(3e4)\n",
    "\n",
    "dataset_name = 'gesture'\n",
    "slicing_time_window = 1e6\n",
    "\n",
    "type_transform = tonic.transforms.NumpyAsType(int)\n",
    "trainset = tonic.datasets.DVSGesture(save_to='../../Data/', train=True, transform=type_transform)\n",
    "testset = tonic.datasets.DVSGesture(save_to='../../Data/', train=False, transform=type_transform)\n",
    "loader = get_sliced_loader(trainset, slicing_time_window, dataset_name, True, only_first=True, kfold=kfold_clust)\n",
    "trainloader = get_sliced_loader(trainset, slicing_time_window, dataset_name, True, only_first=True, kfold=kfold_test)\n",
    "num_sample_train = len(trainloader)\n",
    "testloader = get_sliced_loader(testset, slicing_time_window, dataset_name, False, only_first=True, kfold=kfold_test)\n",
    "num_sample_test = len(testloader)\n",
    "n_classes = len(testset.classes)\n",
    "print(f'number of samples in the training set: {len(trainloader)}')\n",
    "print(f'number of samples in the testing set: {len(testloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ce802c4-e57b-4b22-98cf-0c5fd47633ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For tau equal: 1000.0\n",
      "44 207\n",
      "[0.29545454545454547]\n",
      "For tau equal: 2000.0\n",
      "44 208\n",
      "[0.29545454545454547, 0.5909090909090909]\n",
      "For tau equal: 3000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                         | 0/99 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m path \u001b[38;5;241m=\u001b[39m record_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnetworks/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mhots\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(path):\n\u001b[0;32m---> 30\u001b[0m     hots\u001b[38;5;241m.\u001b[39mclustering(loader, trainset\u001b[38;5;241m.\u001b[39mordering, filtering_threshold \u001b[38;5;241m=\u001b[39m filtering_threshold, ts_batch_size \u001b[38;5;241m=\u001b[39m ts_batch_size, device \u001b[38;5;241m=\u001b[39m device)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#hots.plotlayers()\u001b[39;00m\n\u001b[1;32m     33\u001b[0m hots\u001b[38;5;241m.\u001b[39mcoding(trainloader, trainset\u001b[38;5;241m.\u001b[39mordering, trainset\u001b[38;5;241m.\u001b[39mclasses, filtering_threshold \u001b[38;5;241m=\u001b[39m filtering_threshold, ts_batch_size \u001b[38;5;241m=\u001b[39m ts_batch_size, device \u001b[38;5;241m=\u001b[39m device, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/homhots/hotsline/hots/network.py:84\u001b[0m, in \u001b[0;36mnetwork.clustering\u001b[0;34m(self, loader, ordering, filtering_threshold, ts_batch_size, device, record)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m load_nb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nb_batch):\n\u001b[1;32m     83\u001b[0m     all_ts, ind_filtered_timesurface, previous_timestamp \u001b[38;5;241m=\u001b[39m timesurface(events, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msensor_size[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msensor_size[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_pola[L]), ordering, tau \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtau[L], surface_dimensions\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR[L]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR[L]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m], filtering_threshold \u001b[38;5;241m=\u001b[39m filtering_threshold[L], ts_batch_size \u001b[38;5;241m=\u001b[39m ts_batch_size, load_number \u001b[38;5;241m=\u001b[39m load_nb, previous_timestamp \u001b[38;5;241m=\u001b[39m previous_timestamp, device \u001b[38;5;241m=\u001b[39m device)\n\u001b[0;32m---> 84\u001b[0m     n_star, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mL\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_ts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhstack([outputs,n_star]) \u001b[38;5;28;01mif\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m n_star\n\u001b[1;32m     86\u001b[0m     ind_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhstack([ind_outputs,ind_filtered_timesurface\u001b[38;5;241m+\u001b[39mload_nb\u001b[38;5;241m*\u001b[39mts_batch_size]) \u001b[38;5;28;01mif\u001b[39;00m ind_outputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m ind_filtered_timesurface\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/homhots/hotsline/hots/layer.py:24\u001b[0m, in \u001b[0;36mhotslayer.forward\u001b[0;34m(self, all_ts, clustering_flag, layer_threshold)\u001b[0m\n\u001b[1;32m     22\u001b[0m beta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynapses(ts)\u001b[38;5;241m/\u001b[39m(torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynapses\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhomeo_flag:\n\u001b[0;32m---> 24\u001b[0m     beta_homeo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhomeo_gain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynapses(ts)\u001b[38;5;241m/\u001b[39m(torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynapses\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m     25\u001b[0m     n_star_ev \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(beta_homeo)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/homhots/hotsline/hots/layer.py:13\u001b[0m, in \u001b[0;36mhotslayer.homeo_gain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhomeo_gain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     12\u001b[0m     lambda_homeo \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.25\u001b[39m\n\u001b[0;32m---> 13\u001b[0m     gain \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlambda_homeo\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcumhisto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcumhisto\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcumhisto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gain\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "name = 'homeohots'\n",
    "homeo = True\n",
    "timestr = '2023-01-04'\n",
    "device = 'cuda'\n",
    "\n",
    "R_first = [4]\n",
    "N_layers = [2]\n",
    "n_first = [16]\n",
    "tau_first = [1e3, 2e3, 3e3, 4e3, 5e3, 6e3]\n",
    "\n",
    "scores, parameters = [], []\n",
    "\n",
    "for lay in N_layers:\n",
    "    for R in R_first:\n",
    "        for tau in tau_first:\n",
    "            for N_neuron in n_first:\n",
    "                Rz = [R*2**Nl for Nl in range(lay)]\n",
    "                N_neuronz = [N_neuron*2**Nl for Nl in range(lay)]\n",
    "                N_neuronz = [64, 16]\n",
    "                N_pola = N_neuronz.copy()\n",
    "                N_pola.insert(0,2)\n",
    "                tauz = [tau*N_pola[Nl] for Nl in range(lay)]\n",
    "                print(f'For tau equal: {tau}')\n",
    "                \n",
    "                hots = network(name, dataset_name, timestr, trainset.sensor_size, nb_neurons = N_neuronz, tau = tauz, R = Rz, homeo = homeo, record_path=record_path)\n",
    "                initial_name = hots.name\n",
    "                filtering_threshold = [2*Rz[L] for L in range(len(Rz))]\n",
    "                path = record_path+'networks/'+hots.name+'.pkl'\n",
    "                if not os.path.exists(path):\n",
    "                    hots.clustering(loader, trainset.ordering, filtering_threshold = filtering_threshold, ts_batch_size = ts_batch_size, device = device)\n",
    "                #hots.plotlayers()\n",
    "                \n",
    "                hots.coding(trainloader, trainset.ordering, trainset.classes, filtering_threshold = filtering_threshold, ts_batch_size = ts_batch_size, device = device, training=True, verbose=False)\n",
    "                hots.coding(testloader, testset.ordering, testset.classes, filtering_threshold = filtering_threshold, ts_batch_size = ts_batch_size, device = device, training=False, verbose=False)\n",
    "                \n",
    "                jitter = (None, None)\n",
    "\n",
    "                train_path = f'{record_path}output/train/{hots.name}_{num_sample_train}_{jitter}/'\n",
    "                test_path = f'{record_path}output/test/{hots.name}_{num_sample_test}_{jitter}/'\n",
    "\n",
    "                testset_output = HOTS_Dataset(test_path, testset.sensor_size, testset.classes, transform=type_transform, dtype=trainset.dtype)\n",
    "                trainset_output = HOTS_Dataset(train_path, trainset.sensor_size, trainset.classes, transform=type_transform, dtype=trainset.dtype)\n",
    "                print(len(testset_output),len(trainset_output))\n",
    "                \n",
    "                score = make_histogram_classification(trainset_output, testset_output, N_neuronz[-1])\n",
    "                \n",
    "                scores.append(score)\n",
    "                print(scores)\n",
    "                \n",
    "                parameters.append([lay, R, tau, N_neuron])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91893d83-535f-4d2a-8fa7-443b68528e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(scores)):\n",
    "    plt.semilogx(parameters[i][2], scores[i], 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c2c536d-49da-42e5-9be0-ac954161c148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hots.plotlayers();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff7c35c-e800-435c-afa4-b52c5f68366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'homeohots'\n",
    "homeo = True\n",
    "timestr = '2023-01-04'\n",
    "\n",
    "R_first = [4]\n",
    "N_layers = [2]\n",
    "n_first = [16]\n",
    "tau_first = [1.5e3]\n",
    "\n",
    "scores, parameters = [], []\n",
    "\n",
    "for lay in N_layers:\n",
    "    for R in R_first:\n",
    "        for tau in tau_first:\n",
    "            for N_neuron in n_first:\n",
    "                Rz = [R*2**Nl for Nl in range(lay)]\n",
    "                N_neuronz = [64,32]#[N_neuron*2**Nl for Nl in range(lay)]\n",
    "                N_pola = N_neuronz.copy()\n",
    "                N_pola.insert(0,2)\n",
    "                tauz = [tau*N_pola[Nl] for Nl in range(lay)]\n",
    "                print(f'For tau equal: {tau}')\n",
    "                \n",
    "                hots = network(name, dataset_name, timestr, trainset.sensor_size, nb_neurons = N_neuronz, tau = tauz, R = Rz, homeo = homeo, record_path=record_path)\n",
    "                initial_name = hots.name\n",
    "                filtering_threshold = [2*Rz[L] for L in range(len(Rz))]\n",
    "                path = record_path+'networks/'+hots.name+'.pkl'\n",
    "                if not os.path.exists(path):\n",
    "                    hots.clustering(loader, trainset.ordering, filtering_threshold = filtering_threshold, device = 'cpu')\n",
    "                #hots.plotlayers()\n",
    "                \n",
    "                hots.coding(trainloader, trainset.ordering, trainset.classes, filtering_threshold = filtering_threshold, training=True, verbose=False)\n",
    "                hots.coding(testloader, testset.ordering, testset.classes, filtering_threshold = filtering_threshold, training=False, verbose=False)\n",
    "                \n",
    "                jitter = (None, None)\n",
    "\n",
    "                train_path = f'{record_path}output/train/{hots.name}_{num_sample_train}_{jitter}/'\n",
    "                test_path = f'{record_path}output/test/{hots.name}_{num_sample_test}_{jitter}/'\n",
    "\n",
    "                testset_output = HOTS_Dataset(test_path, testset.sensor_size, testset.classes, transform=type_transform, dtype=trainset.dtype)\n",
    "                trainset_output = HOTS_Dataset(train_path, trainset.sensor_size, trainset.classes, transform=type_transform, dtype=trainset.dtype)\n",
    "                print(len(testset_output),len(trainset_output))\n",
    "                \n",
    "                score = make_histogram_classification(trainset_output, testset_output, N_neuronz[-1]) \n",
    "                \n",
    "                scores.append(score)\n",
    "                print(scores)\n",
    "                \n",
    "                parameters.append([lay, R, tau, N_neuron])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4950206-7429-4e86-8138-6f112f591156",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = classif_layer.linear.weight.data.cpu().numpy()\n",
    "fig, ax = plt.subplots(N_output_neurons, kernels.shape[0], figsize=(30, 90))\n",
    "for n in range(kernels.shape[0]):â€™z\n",
    "    kernel = kernels[n].reshape(trainset.sensor_size[0],trainset.sensor_size[1], N_output_neurons)\n",
    "    for p in range(N_output_neurons):\n",
    "        ax[p, n].imshow(kernel[:,:,p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc6ef67-582c-473d-be02-a93885437f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tonic, torch, os\n",
    "from hots.network import network\n",
    "from hots.utils import apply_jitter, get_loader, get_sliced_loader, make_histogram_classification, HOTS_Dataset, fit_mlr, predict_mlr, score_classif_events\n",
    "import numpy as np\n",
    "\n",
    "print(f'Tonic version installed -> {tonic.__version__}')\n",
    "\n",
    "print(f'Number of GPU devices available: {torch.cuda.device_count()}')\n",
    "for N_gpu in range(torch.cuda.device_count()):\n",
    "    print(f'GPU {N_gpu+1} named {torch.cuda.get_device_name(N_gpu)}')\n",
    "    \n",
    "kfold_test = None\n",
    "kfold_clust = 10\n",
    "ts_batch_size = 1000\n",
    "\n",
    "dataset_name = 'gesture'\n",
    "slicing_time_window = 1e6\n",
    "\n",
    "type_transform = tonic.transforms.NumpyAsType(int)\n",
    "trainset = tonic.datasets.DVSGesture(save_to='../../Data/', train=True, transform=type_transform)\n",
    "testset = tonic.datasets.DVSGesture(save_to='../../Data/', train=False, transform=type_transform)\n",
    "loader = get_sliced_loader(trainset, slicing_time_window, dataset_name, True, only_first=True, kfold=kfold_clust)\n",
    "trainloader = get_sliced_loader(trainset, slicing_time_window, dataset_name, True, only_first=True, kfold=kfold_test)\n",
    "num_sample_train = len(trainloader)\n",
    "testloader = get_sliced_loader(testset, slicing_time_window, dataset_name, False, only_first=True, kfold=kfold_test)\n",
    "num_sample_test = len(testloader)\n",
    "n_classes = len(testset.classes)\n",
    "print(f'number of samples in the training set: {len(trainloader)}')\n",
    "print(f'number of samples in the testing set: {len(testloader)}')\n",
    "\n",
    "name = 'homeohots'\n",
    "homeo = True\n",
    "timestr = '2022-04-22'\n",
    "\n",
    "Rz = [4, 8]\n",
    "N_neuronz = [16, 32]\n",
    "tauz = [5e4*2, 5e4*16]\n",
    "\n",
    "hots = network(name, dataset_name, timestr, trainset.sensor_size, nb_neurons = N_neuronz, tau = tauz, R = Rz, homeo = homeo)\n",
    "\n",
    "#initial_name = hots.name\n",
    "\n",
    "filtering_threshold = [2*Rz[L] for L in range(len(Rz))]\n",
    "if not os.path.exists('../Records/'):\n",
    "    os.mkdir('../Records/')\n",
    "    os.mkdir('../Records/networks/')\n",
    "path = '../Records/networks/'+hots.name+'.pkl'\n",
    "if not os.path.exists(path):\n",
    "    hots.clustering(loader, trainset.ordering, filtering_threshold = filtering_threshold)\n",
    "    \n",
    "jitter = (None, None)\n",
    "num_workers = 0\n",
    "learning_rate = 0.0001\n",
    "beta1, beta2 = 0.9, 0.999\n",
    "betas = (beta1, beta2)\n",
    "num_epochs = 11#2 ** 5 + 1\n",
    "N_output_neurons = N_neuronz[-1]\n",
    "ts_size = (trainset.sensor_size[0],trainset.sensor_size[1],N_output_neurons)\n",
    "tau_cla_list = [1e5, 5e5, 1e6, 5e6, 1e7, 5e7, 1e8]\n",
    "\n",
    "train_path = f'../Records/output/train/{hots.name}_{num_sample_train}_{jitter}/'\n",
    "test_path = f'../Records/output/test/{hots.name}_{num_sample_test}_{jitter}/'\n",
    "\n",
    "print(hots.name)\n",
    "\n",
    "hots.coding(trainloader, trainset.ordering, trainset.classes, training=True, verbose=False)\n",
    "hots.coding(testloader, testset.ordering, testset.classes, training=False, verbose=False)\n",
    "\n",
    "drop_proba = .9\n",
    "if drop_proba:\n",
    "    drop_transform = tonic.transforms.DropEvent(p = drop_proba)\n",
    "    full_drop_transform = tonic.transforms.Compose([drop_transform, type_transform])\n",
    "else: full_drop_transform = type_transform\n",
    "\n",
    "kfold_mlr = 10\n",
    "\n",
    "trainset_output = HOTS_Dataset(train_path, trainset.sensor_size, trainset.classes, dtype=trainset.dtype, transform=full_drop_transform)\n",
    "trainoutputloader = get_loader(trainset_output, kfold = kfold_mlr)\n",
    "testset_output = HOTS_Dataset(test_path, testset.sensor_size, testset.classes, dtype=testset.dtype, transform=type_transform)\n",
    "testoutputloader = get_loader(testset_output, kfold = kfold_mlr)\n",
    "\n",
    "score = make_histogram_classification(trainset_output, testset_output, N_neuronz[-1])\n",
    "score_nohomeo = make_histogram_classification(trainset_output, testset_output, N_neuronz[-1])\n",
    "\n",
    "print(score, score_nohomeo)\n",
    "\n",
    "for tau_cla in tau_cla_list:\n",
    "\n",
    "    model_path = f'../Records/networks/{hots.name}_{tau_cla}_{learning_rate}_{betas}_{num_epochs}_{jitter}_{drop_proba}.pkl'\n",
    "    results_path = f'../Records/LR_results/{hots.name}_{tau_cla}_{learning_rate}_{betas}_{num_epochs}_{jitter}_{drop_proba}.pkl'\n",
    "    print(f'Number of samples in the trainset set: {len(trainoutputloader)}')\n",
    "    \n",
    "    print(len(trainoutputloader))\n",
    "    \n",
    "    classif_layer, losses = fit_mlr(trainoutputloader, model_path, tau_cla, learning_rate, betas, num_epochs, ts_size, trainset.ordering, len(trainset.classes), ts_batch_size = ts_batch_size)\n",
    "    likelihood, true_target, timestamps = predict_mlr(classif_layer,tau_cla,testoutputloader,results_path,ts_size,testset_output.ordering,  ts_batch_size = ts_batch_size)\n",
    "    meanac, onlinac, lastac = score_classif_events(likelihood, true_target, n_classes, original_accuracy = score, original_accuracy_nohomeo = score_nohomeo)#, figure_name = 'nmnist_online.pdf')\n",
    "    print(f'For tau = {tau_cla} last accuracy: {lastac*100}% - mean accuracy: {meanac*100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64651590-32cc-448b-8a5f-08712cb70972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
