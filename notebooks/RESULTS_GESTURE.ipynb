{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "146e9eb1-7f15-4122-a866-cd3061b73da0",
   "metadata": {},
   "source": [
    "# RESULTS DVS Gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a75ff8-780a-400b-9925-515f4a2274cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6346880-ad3c-4a2c-a39a-1a8842c3ac3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/INT/grimaldi.a/Documents/projets/HOTS/hotsline/hots\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": " (:classq1() method: bad call flags",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3096555/4200977152.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../hots'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtonic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmlrlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m:  (:classq1() method: bad call flags"
     ]
    }
   ],
   "source": [
    "%cd ../hots\n",
    "import tonic, torch, os, pickle\n",
    "from tqdm import tqdm\n",
    "from network import network\n",
    "from layer import mlrlayer\n",
    "from timesurface import timesurface\n",
    "from utils import apply_jitter, get_loader, get_sliced_loader, make_histogram_classification, HOTS_Dataset, fit_mlr, predict_mlr, score_classif_events, plotjitter, printfig\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(f'Tonic version installed -> {tonic.__version__}')\n",
    "\n",
    "print(f'Number of GPU devices available: {torch.cuda.device_count()}')\n",
    "for N_gpu in range(torch.cuda.device_count()):\n",
    "    print(f'GPU {N_gpu+1} named {torch.cuda.get_device_name(N_gpu)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae45cc7-c96c-4c5f-8b9b-efa613afd9b3",
   "metadata": {},
   "source": [
    "## Loading of the dataset for the clustering phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe228881-0acd-422e-9376-966d47b0425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_test = None\n",
    "kfold_clust = 10\n",
    "ts_batch_size = 2000\n",
    "\n",
    "dataset_name = 'gesture'\n",
    "slicing_time_window = 1e6\n",
    "\n",
    "type_transform = tonic.transforms.NumpyAsType(int)\n",
    "trainset = tonic.datasets.DVSGesture(save_to='../../Data/', train=True, transform=type_transform)\n",
    "testset = tonic.datasets.DVSGesture(save_to='../../Data/', train=False, transform=type_transform)\n",
    "loader = get_sliced_loader(trainset, slicing_time_window, dataset_name, True, only_first=True, kfold=kfold_clust)\n",
    "trainloader = get_sliced_loader(trainset, slicing_time_window, dataset_name, True, only_first=True, kfold=kfold_test)\n",
    "num_sample_train = len(trainloader)\n",
    "testloader = get_sliced_loader(testset, slicing_time_window, dataset_name, False, only_first=True, kfold=kfold_test)\n",
    "num_sample_test = len(testloader)\n",
    "n_classes = len(testset.classes)\n",
    "print(f'number of samples in the training set: {len(trainloader)}')\n",
    "print(f'number of samples in the testing set: {len(testloader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce771bc-ad2d-45c4-ba80-0a28862f07fe",
   "metadata": {},
   "source": [
    "## Initialization of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caf366e-fc63-4030-868b-a57babe598de",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'homeohots'\n",
    "homeo = True\n",
    "timestr = '2022-04-22'\n",
    "dataset_name = 'gesture'\n",
    "\n",
    "Rz = [4, 8]\n",
    "N_neuronz = [16, 32]\n",
    "tauz = [5e4*2, 5e4*16]\n",
    "\n",
    "hots = network(name, dataset_name, timestr, trainset.sensor_size, nb_neurons = N_neuronz, tau = tauz, R = Rz, homeo = homeo)\n",
    "\n",
    "initial_name = hots.name\n",
    "\n",
    "name_nohomeo = 'hots'\n",
    "hots_nohomeo = network(name, dataset_name, timestr, trainset.sensor_size, nb_neurons = N_neuronz, tau = tauz, R = Rz, homeo = False)\n",
    "\n",
    "initial_name_nohomeo = hots_nohomeo.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804365ce-3c09-40a8-90ad-f2471961b169",
   "metadata": {},
   "source": [
    "##Â Unsupervised clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7064b789-7876-4611-8d34-3a5a4d62e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering_threshold = [2*Rz[L] for L in range(len(Rz))]\n",
    "if not os.path.exists('../Records/'):\n",
    "    os.mkdir('../Records/')\n",
    "    os.mkdir('../Records/networks/')\n",
    "path = '../Records/networks/'+hots.name+'.pkl'\n",
    "if not os.path.exists(path):\n",
    "    hots.clustering(loader, trainset.ordering, filtering_threshold = filtering_threshold)\n",
    "path_nohomeo = '../Records/networks/'+hots_nohomeo.name+'.pkl'\n",
    "if not os.path.exists(path_nohomeo):\n",
    "    hots_nohomeo.clustering(loader, trainset.ordering, filtering_threshold = filtering_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0361ae-8651-4ca6-95db-d3161988f90c",
   "metadata": {},
   "source": [
    "## Training of the classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad1021c-e642-432f-a6a5-80aee959e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter = (None, None)\n",
    "\n",
    "hots.coding(trainloader, trainset.ordering, trainset.classes, filtering_threshold = filtering_threshold, training=True, verbose=False)\n",
    "hots.coding(testloader, trainset.ordering, trainset.classes, filtering_threshold = filtering_threshold, training=False, verbose=False)\n",
    "\n",
    "hots_nohomeo.coding(trainloader, trainset.ordering, trainset.classes, filtering_threshold = filtering_threshold, training=True, verbose=False)\n",
    "hots_nohomeo.coding(testloader, testset.ordering, testset.classes, filtering_threshold = filtering_threshold, training=False, jitter=jitter, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a911b9-b781-4e79-a4f9-494dd90615ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "learning_rate = 0.0001\n",
    "beta1, beta2 = 0.9, 0.999\n",
    "betas = (beta1, beta2)\n",
    "num_epochs = 2 ** 5 + 1\n",
    "N_output_neurons = N_neuronz[-1]\n",
    "ts_size = (trainset.sensor_size[0],trainset.sensor_size[1],N_output_neurons)\n",
    "tau_cla = 2e8\n",
    "drop_proba = .9\n",
    "\n",
    "train_path = f'../Records/output/train/{hots.name}_{num_sample_train}_{jitter}/'\n",
    "test_path = f'../Records/output/test/{hots.name}_{num_sample_test}_{jitter}/'\n",
    "model_path = f'../Records/networks/{hots.name}_{tau_cla}_{learning_rate}_{betas}_{num_epochs}_{jitter}.pkl'\n",
    "results_path = f'../Records/LR_results/{hots.name}_{tau_cla}_{learning_rate}_{betas}_{num_epochs}_{jitter}.pkl'\n",
    "\n",
    "hots.coding(trainloader, trainset.ordering, trainset.classes, training=True, verbose=False)\n",
    "hots.coding(testloader, testset.ordering, testset.classes, training=False, verbose=False)\n",
    "\n",
    "drop_transform = tonic.transforms.DropEvent(p = drop_proba)\n",
    "\n",
    "trainset_output = HOTS_Dataset(train_path, trainset.sensor_size, trainset.classes, dtype=trainset.dtype, transform=tonic.transforms.Compose([drop_transform, type_transform]))\n",
    "trainoutputloader = get_loader(trainset_output)\n",
    "testset_output = HOTS_Dataset(test_path, testset.sensor_size, testset.classes, dtype=testset.dtype, transform=type_transform)\n",
    "testoutputloader = get_loader(testset_output)\n",
    "\n",
    "classif_layer, losses = fit_mlr(trainoutputloader, model_path, tau_cla, learning_rate, betas, num_epochs, ts_size, trainset.ordering, len(trainset.classes), ts_batch_size = ts_batch_size)\n",
    "\n",
    "hots_nohomeo.coding(trainloader, trainset.ordering, trainset.classes, training=True, verbose=False)\n",
    "\n",
    "train_path_nohomeo = f'../Records/output/train/{hots_nohomeo.name}_{num_sample_train}_{jitter}/'\n",
    "test_path_nohomeo = f'../Records/output/test/{hots_nohomeo.name}_{num_sample_test}_{jitter}/'\n",
    "\n",
    "trainset_output_nohomeo = HOTS_Dataset(train_path_nohomeo, trainset.sensor_size, trainset.classes, dtype=trainset.dtype, transform=type_transform)\n",
    "\n",
    "hots_nohomeo.coding(testloader, testset.ordering, testset.classes, training=False, jitter=jitter, verbose=False)\n",
    "testset_output_nohomeo = HOTS_Dataset(test_path_nohomeo, trainset.sensor_size, trainset.classes, dtype=trainset.dtype, transform=type_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97301a0-bdce-4595-95f0-ae50fd56b372",
   "metadata": {},
   "source": [
    "## Online Inference (Figure 4-(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e385305b-1b7a-4f42-91bb-d308dd5521ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood, true_target, timestamps = predict_mlr(classif_layer,tau_cla,testoutputloader,results_path,ts_size,testset_output.ordering,  ts_batch_size = ts_batch_size)\n",
    "score = make_histogram_classification(trainset_output, testset_output, N_neuronz[-1])\n",
    "score_nohomeo = make_histogram_classification(trainset_output_nohomeo, testset_output_nohomeo, N_neuronz[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5549ad4b-36a4-44bc-88ee-692495809bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_threshold = None\n",
    "\n",
    "meanac, onlinac, lastac = score_classif_events(likelihood, true_target, n_classes, thres = mlr_threshold, original_accuracy = score, original_accuracy_nohomeo = score_nohomeo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33777f05-8ecb-4503-ba89-23258a9db097",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_threshold = .99\n",
    "\n",
    "meanac, onlinac, lastac = score_classif_events(likelihood, true_target, n_classes, thres = mlr_threshold, original_accuracy = score, original_accuracy_nohomeo = score_nohomeo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75378b6a-ba60-4813-afb9-cf7405f24043",
   "metadata": {},
   "source": [
    "## Robustness to spatial jitter (Figure 5-(b)-(up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5ca5fe-2166-43d0-b965-87fe53bd7d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def run_jitter(min_jitter, max_jitter, jitter_type, hots, hots_nohomeo, dataset_name, trainset_output, filtering_threshold = None, kfold = None, nb_trials = 10, nb_points = 20, fitting = True, figure_name = None, verbose = False):\n",
    "    \n",
    "    initial_name = copy.copy(hots.name)\n",
    "    initial_name_nohomeo = copy.copy(hots_nohomeo.name)\n",
    "    \n",
    "    n_classes = len(trainset_output.classes)\n",
    "    n_output_neurons = len(hots.layers[-1].cumhisto)\n",
    "    ts_size = [trainset_output.sensor_size[0],trainset_output.sensor_size[1],n_output_neurons]\n",
    "    \n",
    "    ts_batch_size = None\n",
    "    \n",
    "    type_transform = tonic.transforms.NumpyAsType(int)\n",
    "    \n",
    "    if not os.path.exists('../Records/jitter_results/'):\n",
    "        os.mkdir('../Records/jitter_results/')\n",
    "    if jitter_type=='temporal':\n",
    "        std_jit_t = np.logspace(min_jitter,max_jitter,nb_points)\n",
    "        jitter_values = std_jit_t\n",
    "    else:\n",
    "        std_jit_s = np.linspace(min_jitter,max_jitter,nb_points)\n",
    "        var_jit_s = std_jit_s**2\n",
    "        jitter_values = var_jit_s\n",
    "\n",
    "    jitter_path = f'../Records/jitter_results/{initial_name}_{nb_trials}_{min_jitter}_{max_jitter}_{kfold}_{nb_points}'\n",
    "\n",
    "    if not os.path.exists(jitter_path+'.npz'):\n",
    "\n",
    "        torch.set_default_tensor_type(\"torch.DoubleTensor\")\n",
    "\n",
    "        for trial in tqdm(range(nb_trials)):\n",
    "            for ind_jit, jitter_val in enumerate(jitter_values):\n",
    "                if jitter_val==0:\n",
    "                    jitter = (None,None)\n",
    "                else:\n",
    "                    if jitter_type=='temporal':\n",
    "                        jitter = (None,jitter_val)\n",
    "                    else:\n",
    "                        jitter = (jitter_val,None)\n",
    "                        \n",
    "                hots.name = initial_name+f'_{trial}'\n",
    "                hots_nohomeo.name = initial_name_nohomeo+f'_{trial}'\n",
    "\n",
    "                if jitter_type=='temporal':\n",
    "                    temporal_jitter_transform = tonic.transforms.TimeJitter(std = jitter_val, clip_negative = True, sort_timestamps = True)\n",
    "                    transform_full = tonic.transforms.Compose([temporal_jitter_transform, type_transform])\n",
    "                else:\n",
    "                    spatial_jitter_transform = tonic.transforms.SpatialJitter(sensor_size = trainset_output.sensor_size, variance_x = jitter_val, variance_y = jitter_val, clip_outliers = True)\n",
    "                    transform_full = tonic.transforms.Compose([spatial_jitter_transform, type_transform])\n",
    "                    \n",
    "                if dataset_name=='poker':\n",
    "                    testset = tonic.datasets.POKERDVS(save_to='../../Data/', train=False, transform=transform_full)\n",
    "                    testloader = get_loader(testset, kfold = kfold)\n",
    "                elif dataset_name=='nmnist':\n",
    "                    testset = tonic.datasets.NMNIST(save_to='../../Data/', train=False, transform=transform_full)\n",
    "                    testloader = get_loader(testset, kfold = kfold)\n",
    "                elif dataset_name=='gesture':\n",
    "                    testset = tonic.datasets.DVSGesture(save_to='../../Data/', train=False, transform=transform_full)\n",
    "                    testloader = get_sliced_loader(testset, slicing_time_window, dataset_name, False, only_first=True, kfold=kfold)\n",
    "                    \n",
    "                print(f'trial number : {trial} - jitter : {jitter}')\n",
    "                hots.coding(testloader, trainset_output.ordering, testset.classes, training=False, jitter = jitter, filtering_threshold = filtering_threshold, ts_batch_size = ts_batch_size, verbose=False)\n",
    "                hots_nohomeo.coding(testloader, trainset_output.ordering, testset.classes, training=False, jitter=jitter, filtering_threshold=filtering_threshold, ts_batch_size = ts_batch_size, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8990223-8d4e-44ff-ba9e-924dd32bdf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_jitter = 10\n",
    "nb_trials = 1\n",
    "nb_points = 5\n",
    "\n",
    "filtering_threshold = [5*Rz[L] for L in range(len(Rz))]\n",
    "\n",
    "trainset_output_jitter = HOTS_Dataset(train_path, trainset.sensor_size, trainset.classes, dtype=trainset.dtype, transform=type_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888bc1b-972b-4420-816f-f430673c7e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_spatial_jitter_min = 0\n",
    "standard_spatial_jitter_max = 10\n",
    "run_jitter(standard_spatial_jitter_min, standard_spatial_jitter_max, 'spatial', hots, hots_nohomeo, dataset_name, trainset_output_jitter, kfold = kfold_jitter, nb_trials = nb_trials, nb_points = nb_points, filtering_threshold = filtering_threshold, fitting = False);"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d844dcfb-8ed7-484a-8254-d95bb5a5f2fb",
   "metadata": {},
   "source": [
    "standard_spatial_jitter_min = 0\n",
    "standard_spatial_jitter_max = 10\n",
    "run_jitter(standard_spatial_jitter_min, standard_spatial_jitter_max, 'spatial', hots, hots_nohomeo, dataset_name, trainset_output_jitter, kfold = kfold_jitter, nb_trials = nb_trials, nb_points = nb_points, filtering_threshold = filtering_threshold, fitting = False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ccb161-5b0b-4d03-bb0e-4baa38e4f443",
   "metadata": {},
   "source": [
    "## Robustness to temporal jitter (Figure 5-(b)-(down))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb81605f-0301-4d62-b098-5c9e70c0d9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_temporal_jitter_min = 3\n",
    "standard_temporal_jitter_max = 7\n",
    "run_jitter(standard_temporal_jitter_min, standard_temporal_jitter_max, 'temporal', hots, hots_nohomeo, dataset_name, trainset_output_jitter, kfold = kfold_jitter, nb_trials = nb_trials, nb_points = nb_points, filtering_threshold = filtering_threshold, fitting = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f132db-1fb2-4f56-8d1b-cbc806248b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
