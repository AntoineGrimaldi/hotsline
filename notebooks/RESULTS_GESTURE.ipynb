{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "146e9eb1-7f15-4122-a866-cd3061b73da0",
   "metadata": {},
   "source": [
    "# RESULTS DVS Gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a75ff8-780a-400b-9925-515f4a2274cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6346880-ad3c-4a2c-a39a-1a8842c3ac3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/antoine/homhots/hotsline/hots\n",
      "Tonic version installed -> 1.0.19\n",
      "Number of GPU devices available: 1\n",
      "GPU 1 named GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "%cd ../hots\n",
    "import tonic, torch, os, pickle\n",
    "from tqdm import tqdm\n",
    "from network import network\n",
    "from layer import mlrlayer\n",
    "from timesurface import timesurface\n",
    "from utils import apply_jitter, get_loader, get_sliced_loader, make_histogram_classification, HOTS_Dataset, fit_mlr, predict_mlr, score_classif_events, plotjitter, printfig, online_accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(f'Tonic version installed -> {tonic.__version__}')\n",
    "\n",
    "print(f'Number of GPU devices available: {torch.cuda.device_count()}')\n",
    "for N_gpu in range(torch.cuda.device_count()):\n",
    "    print(f'GPU {N_gpu+1} named {torch.cuda.get_device_name(N_gpu)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae45cc7-c96c-4c5f-8b9b-efa613afd9b3",
   "metadata": {},
   "source": [
    "## Loading of the dataset for the clustering phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe228881-0acd-422e-9376-966d47b0425b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Data/DVSGesture/metadata/gesture_1000_True_True\n",
      "Read metadata from disk.\n",
      "../../Data/DVSGesture/metadata/gesture_1000_True_True\n",
      "Read metadata from disk.\n",
      "../../Data/DVSGesture/metadata/gesture_1000_True_False\n",
      "Read metadata from disk.\n",
      "number of samples in the training set: 1077\n",
      "number of samples in the testing set: 264\n"
     ]
    }
   ],
   "source": [
    "kfold_test = None\n",
    "kfold_clust = 10\n",
    "ts_batch_size = 2000\n",
    "\n",
    "dataset_name = 'gesture'\n",
    "slicing_time_window = 1e6\n",
    "\n",
    "type_transform = tonic.transforms.NumpyAsType(int)\n",
    "trainset = tonic.datasets.DVSGesture(save_to='../../Data/', train=True, transform=type_transform)\n",
    "testset = tonic.datasets.DVSGesture(save_to='../../Data/', train=False, transform=type_transform)\n",
    "loader = get_sliced_loader(trainset, slicing_time_window, dataset_name, True, only_first=True, kfold=kfold_clust)\n",
    "trainloader = get_sliced_loader(trainset, slicing_time_window, dataset_name, True, only_first=True, kfold=kfold_test)\n",
    "num_sample_train = len(trainloader)\n",
    "testloader = get_sliced_loader(testset, slicing_time_window, dataset_name, False, only_first=True, kfold=kfold_test)\n",
    "num_sample_test = len(testloader)\n",
    "n_classes = len(testset.classes)\n",
    "print(f'number of samples in the training set: {len(trainloader)}')\n",
    "print(f'number of samples in the testing set: {len(testloader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce771bc-ad2d-45c4-ba80-0a28862f07fe",
   "metadata": {},
   "source": [
    "## Initialization of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1caf366e-fc63-4030-868b-a57babe598de",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'homeohots'\n",
    "homeo = True\n",
    "timestr = '2022-04-22'\n",
    "dataset_name = 'gesture'\n",
    "\n",
    "Rz = [4, 8]\n",
    "N_neuronz = [16, 32]\n",
    "tauz = [5e4*2, 5e4*16]\n",
    "\n",
    "hots = network(name, dataset_name, timestr, trainset.sensor_size, nb_neurons = N_neuronz, tau = tauz, R = Rz, homeo = homeo)\n",
    "\n",
    "initial_name = hots.name\n",
    "\n",
    "name_nohomeo = 'hots'\n",
    "hots_nohomeo = network(name, dataset_name, timestr, trainset.sensor_size, nb_neurons = N_neuronz, tau = tauz, R = Rz, homeo = False)\n",
    "\n",
    "initial_name_nohomeo = hots_nohomeo.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804365ce-3c09-40a8-90ad-f2471961b169",
   "metadata": {},
   "source": [
    "## Unsupervised clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7064b789-7876-4611-8d34-3a5a4d62e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering_threshold = [2*Rz[L] for L in range(len(Rz))]\n",
    "if not os.path.exists('../Records/'):\n",
    "    os.mkdir('../Records/')\n",
    "    os.mkdir('../Records/networks/')\n",
    "path = '../Records/networks/'+hots.name+'.pkl'\n",
    "if not os.path.exists(path):\n",
    "    hots.clustering(loader, trainset.ordering, filtering_threshold = filtering_threshold)\n",
    "path_nohomeo = '../Records/networks/'+hots_nohomeo.name+'.pkl'\n",
    "if not os.path.exists(path_nohomeo):\n",
    "    hots_nohomeo.clustering(loader, trainset.ordering, filtering_threshold = filtering_threshold)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9844a1e0-9745-4b96-a6f3-bbea2af985b2",
   "metadata": {},
   "source": [
    "hots.plotlayers();\n",
    "hots_nohomeo.plotlayers();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0361ae-8651-4ca6-95db-d3161988f90c",
   "metadata": {},
   "source": [
    "## Training of the classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ad1021c-e642-432f-a6a5-80aee959e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter = (None, None)\n",
    "\n",
    "hots.coding(trainloader, trainset.ordering, trainset.classes, filtering_threshold = filtering_threshold, training=True, verbose=False)\n",
    "hots.coding(testloader, trainset.ordering, trainset.classes, filtering_threshold = filtering_threshold, training=False, verbose=False)\n",
    "\n",
    "hots_nohomeo.coding(trainloader, trainset.ordering, trainset.classes, filtering_threshold = filtering_threshold, training=True, verbose=False)\n",
    "hots_nohomeo.coding(testloader, testset.ordering, testset.classes, filtering_threshold = filtering_threshold, training=False, jitter=jitter, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0a911b9-b781-4e79-a4f9-494dd90615ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Records/networks/2022-04-22_gesture_homeohots_True_[16, 32]_[100000.0, 800000.0]_[4, 8]_100000000.0_0.0001_(0.9, 0.999)_129_0.99_(None, None).pkl\n",
      "device -> cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▊                                                                                                                                                                                                                                   | 1/129 [08:08<17:22:54, 488.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch number 0: 0.545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███▌                                                                                                                                                                                                                                 | 2/129 [16:19<17:16:27, 489.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch number 1: 0.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█████▎                                                                                                                                                                                                                               | 3/129 [24:29<17:08:49, 489.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch number 2: 0.436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███████                                                                                                                                                                                                                              | 4/129 [32:39<17:00:41, 489.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch number 3: 0.449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███████                                                                                                                                                                                                                              | 4/129 [34:02<17:43:54, 510.67s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m testset_output \u001b[38;5;241m=\u001b[39m HOTS_Dataset(test_path, testset\u001b[38;5;241m.\u001b[39msensor_size, testset\u001b[38;5;241m.\u001b[39mclasses, dtype\u001b[38;5;241m=\u001b[39mtestset\u001b[38;5;241m.\u001b[39mdtype, transform\u001b[38;5;241m=\u001b[39mtype_transform)\n\u001b[1;32m     24\u001b[0m testoutputloader \u001b[38;5;241m=\u001b[39m get_loader(testset_output)\n\u001b[0;32m---> 26\u001b[0m classif_layer, losses \u001b[38;5;241m=\u001b[39m \u001b[43mfit_mlr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainoutputloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau_cla\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbetas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mordering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrainset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mts_batch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m train_path_nohomeo \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Records/output/train/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhots_nohomeo\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_sample_train\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjitter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     29\u001b[0m test_path_nohomeo \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Records/output/test/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhots_nohomeo\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_sample_test\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjitter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/homhots/hotsline/hots/utils.py:329\u001b[0m, in \u001b[0;36mfit_mlr\u001b[0;34m(loader, model_path, tau_cla, learning_rate, betas, num_epochs, ts_size, ordering, n_classes, ts_batch_size, device)\u001b[0m\n\u001b[1;32m    327\u001b[0m         torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 329\u001b[0m     X, ind_filtered \u001b[38;5;241m=\u001b[39m \u001b[43mtimesurface\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mts_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mordering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtau_cla\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m     X, label \u001b[38;5;241m=\u001b[39m X, label\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    331\u001b[0m     n_events \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/homhots/hotsline/hots/timesurface.py:41\u001b[0m, in \u001b[0;36mtimesurface\u001b[0;34m(events, sensor_size, ordering, surface_dimensions, tau, decay, filtering_threshold, ts_batch_size, load_number, previous_timestamp, device, dtype)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m     timestamp_memory \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m tau \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 41\u001b[0m     all_surfaces \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevents\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msensor_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msurface_dimensions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43msurface_dimensions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     events_list \u001b[38;5;241m=\u001b[39m events\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(events_list):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_workers = 0\n",
    "learning_rate = 0.0001\n",
    "beta1, beta2 = 0.9, 0.999\n",
    "betas = (beta1, beta2)\n",
    "num_epochs = 2 ** 7 + 1\n",
    "N_output_neurons = N_neuronz[-1]\n",
    "ts_size = (trainset.sensor_size[0],trainset.sensor_size[1],N_output_neurons)\n",
    "tau_cla = 1e8\n",
    "#tau_cla = 2e8\n",
    "drop_proba = .99\n",
    "\n",
    "train_path = f'../Records/output/train/{hots.name}_{num_sample_train}_{jitter}/'\n",
    "test_path = f'../Records/output/test/{hots.name}_{num_sample_test}_{jitter}/'\n",
    "model_path = f'../Records/networks/{hots.name}_{tau_cla}_{learning_rate}_{betas}_{num_epochs}_{drop_proba}_{jitter}.pkl'\n",
    "results_path = f'../Records/LR_results/{hots.name}_{tau_cla}_{learning_rate}_{betas}_{num_epochs}_{drop_proba}_{jitter}.pkl'\n",
    "print(model_path)\n",
    "\n",
    "drop_transform = tonic.transforms.DropEvent(p = drop_proba)\n",
    "kfold_mlr = None\n",
    "\n",
    "trainset_output = HOTS_Dataset(train_path, trainset.sensor_size, trainset.classes, dtype=trainset.dtype, transform=tonic.transforms.Compose([drop_transform, type_transform]))\n",
    "trainoutputloader = get_loader(trainset_output, kfold = kfold_mlr)\n",
    "testset_output = HOTS_Dataset(test_path, testset.sensor_size, testset.classes, dtype=testset.dtype, transform=type_transform)\n",
    "testoutputloader = get_loader(testset_output)\n",
    "\n",
    "classif_layer, losses = fit_mlr(trainoutputloader, model_path, tau_cla, learning_rate, betas, num_epochs, ts_size, trainset.ordering, len(trainset.classes), ts_batch_size = ts_batch_size)\n",
    "\n",
    "train_path_nohomeo = f'../Records/output/train/{hots_nohomeo.name}_{num_sample_train}_{jitter}/'\n",
    "test_path_nohomeo = f'../Records/output/test/{hots_nohomeo.name}_{num_sample_test}_{jitter}/'\n",
    "\n",
    "trainset_output_nohomeo = HOTS_Dataset(train_path_nohomeo, trainset.sensor_size, trainset.classes, dtype=trainset.dtype, transform=type_transform)\n",
    "testset_output_nohomeo = HOTS_Dataset(test_path_nohomeo, trainset.sensor_size, trainset.classes, dtype=trainset.dtype, transform=type_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d106a0a-22bc-4355-bd1a-8d38d0c9138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97301a0-bdce-4595-95f0-ae50fd56b372",
   "metadata": {},
   "source": [
    "## Online Inference (Figure 4-(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13ef3cc-d3fa-4834-a41d-880273894407",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = make_histogram_classification(trainset_output, testset_output, N_neuronz[-1])\n",
    "score_nohomeo = make_histogram_classification(trainset_output_nohomeo, testset_output_nohomeo, N_neuronz[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f837711-f0b5-46c5-8771-b67944bf607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score, score_nohomeo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56cd58c-dd2b-41fb-b43a-658f20fb1b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 0.140\n",
    "score_nohomeo = 0.121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5549ad4b-36a4-44bc-88ee-692495809bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_threshold = None\n",
    "onlinac = online_accuracy(classif_layer, tau_cla, testoutputloader, results_path, ts_size, testset_output.ordering, n_classes, mlr_threshold = mlr_threshold, ts_batch_size = ts_batch_size, original_accuracy = score, original_accuracy_nohomeo = score_nohomeo, online_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33777f05-8ecb-4503-ba89-23258a9db097",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_threshold = .9\n",
    "onlinac_thres = online_accuracy(classif_layer, tau_cla, testoutputloader, results_path, ts_size, testset_output.ordering, n_classes, mlr_threshold = mlr_threshold, ts_batch_size = ts_batch_size, original_accuracy = score, original_accuracy_nohomeo = score_nohomeo, online_plot=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d969d5d-5f3c-41dd-8c6d-21afd31daa1b",
   "metadata": {},
   "source": [
    "kernels = classif_layer.linear.weight.data.cpu().numpy()\n",
    "fig, ax = plt.subplots(N_output_neurons, kernels.shape[0], figsize=(30, 90))\n",
    "for n in range(kernels.shape[0]):\n",
    "    kernel = kernels[n].reshape(trainset.sensor_size[0],trainset.sensor_size[1], N_output_neurons)\n",
    "    for p in range(N_output_neurons):\n",
    "        ax[p, n].imshow(kernel[:,:,p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab64083c-db61-4493-be6c-a8b71ad441e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(onlinac[0])\n",
    "plt.semilogx(onlinac_thres[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdaf921-c95d-4692-b217-320af0d29622",
   "metadata": {},
   "outputs": [],
   "source": [
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75378b6a-ba60-4813-afb9-cf7405f24043",
   "metadata": {},
   "source": [
    "## Robustness to spatial jitter (Figure 5-(b)-(up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5ca5fe-2166-43d0-b965-87fe53bd7d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def run_jitter(min_jitter, max_jitter, jitter_type, hots, hots_nohomeo, dataset_name, trainset_output, filtering_threshold = None, kfold = None, nb_trials = 10, nb_points = 20, fitting = True, figure_name = None, verbose = False):\n",
    "    \n",
    "    initial_name = copy.copy(hots.name)\n",
    "    initial_name_nohomeo = copy.copy(hots_nohomeo.name)\n",
    "    \n",
    "    n_classes = len(trainset_output.classes)\n",
    "    n_output_neurons = len(hots.layers[-1].cumhisto)\n",
    "    ts_size = [trainset_output.sensor_size[0],trainset_output.sensor_size[1],n_output_neurons]\n",
    "    \n",
    "    ts_batch_size = None\n",
    "    mlr_threshold = .99\n",
    "    type_transform = tonic.transforms.NumpyAsType(int)\n",
    "    \n",
    "    if not os.path.exists('../Records/jitter_results/'):\n",
    "        os.mkdir('../Records/jitter_results/')\n",
    "    if jitter_type=='temporal':\n",
    "        std_jit_t = np.logspace(min_jitter,max_jitter,nb_points)\n",
    "        jitter_values = std_jit_t\n",
    "    else:\n",
    "        std_jit_s = np.linspace(min_jitter,max_jitter,nb_points)\n",
    "        var_jit_s = std_jit_s**2\n",
    "        jitter_values = var_jit_s\n",
    "\n",
    "    jitter_path = f'../Records/jitter_results/{initial_name}_{nb_trials}_{min_jitter}_{max_jitter}_{kfold}_{nb_points}'\n",
    "\n",
    "    if not os.path.exists(jitter_path+'.npz'):\n",
    "\n",
    "        torch.set_default_tensor_type(\"torch.DoubleTensor\")\n",
    "\n",
    "        for trial in tqdm(range(nb_trials)):\n",
    "            for ind_jit, jitter_val in enumerate(jitter_values):\n",
    "                if jitter_val==0:\n",
    "                    jitter = (None,None)\n",
    "                else:\n",
    "                    if jitter_type=='temporal':\n",
    "                        jitter = (None,jitter_val)\n",
    "                    else:\n",
    "                        jitter = (jitter_val,None)\n",
    "                        \n",
    "                hots.name = initial_name+f'_{trial}'\n",
    "                hots_nohomeo.name = initial_name_nohomeo+f'_{trial}'\n",
    "                \n",
    "                drop_proba = .5\n",
    "\n",
    "                if jitter_type=='temporal':\n",
    "                    temporal_jitter_transform = tonic.transforms.TimeJitter(std = jitter_val, clip_negative = True, sort_timestamps = True)\n",
    "                    transform_full = tonic.transforms.Compose([temporal_jitter_transform, type_transform])\n",
    "                    if drop_proba:\n",
    "                        drop_transform = tonic.transforms.DropEvent(p = drop_proba)\n",
    "                        transform_full = tonic.transforms.Compose([drop_transform, temporal_jitter_transform, type_transform])\n",
    "                else:\n",
    "                    spatial_jitter_transform = tonic.transforms.SpatialJitter(sensor_size = trainset_output.sensor_size, variance_x = jitter_val, variance_y = jitter_val, clip_outliers = True)\n",
    "                    transform_full = tonic.transforms.Compose([spatial_jitter_transform, type_transform])\n",
    "                    if drop_proba:\n",
    "                        drop_transform = tonic.transforms.DropEvent(p = drop_proba)\n",
    "                        transform_full = tonic.transforms.Compose([drop_transform, spatial_jitter_transform, type_transform])\n",
    "                    \n",
    "                if dataset_name=='poker':\n",
    "                    testset = tonic.datasets.POKERDVS(save_to='../../Data/', train=False, transform=transform_full)\n",
    "                    testloader = get_loader(testset, kfold = kfold)\n",
    "                elif dataset_name=='nmnist':\n",
    "                    testset = tonic.datasets.NMNIST(save_to='../../Data/', train=False, transform=transform_full)\n",
    "                    testloader = get_loader(testset, kfold = kfold)\n",
    "                elif dataset_name=='gesture':\n",
    "                    testset = tonic.datasets.DVSGesture(save_to='../../Data/', train=False, transform=transform_full)\n",
    "                    testloader = get_sliced_loader(testset, slicing_time_window, dataset_name, False, only_first=True, kfold=kfold)\n",
    "                    \n",
    "                num_sample_test = len(testloader)\n",
    "                test_path = f'../Records/output/test/{hots.name}_{num_sample_test}_{jitter}/'\n",
    "                test_path_nohomeo = f'../Records/output/test/{hots_nohomeo.name}_{num_sample_test}_{jitter}/'\n",
    "                    \n",
    "                print(test_path)\n",
    "                \n",
    "                hots.coding(testloader, trainset_output.ordering, testset.classes, training=False, jitter = jitter, filtering_threshold = filtering_threshold, ts_batch_size = ts_batch_size, verbose=False)\n",
    "                hots_nohomeo.coding(testloader, trainset_output.ordering, testset.classes, training=False, jitter=jitter, filtering_threshold=filtering_threshold, ts_batch_size = ts_batch_size, verbose=False)\n",
    "                \n",
    "                testset_output = HOTS_Dataset(test_path, trainset_output.sensor_size, trainset_output.classes, dtype=trainset_output.dtype, transform=type_transform)\n",
    "                test_outputloader = get_loader(testset_output, shuffle=False)\n",
    "                \n",
    "                testset_output_nohomeo = HOTS_Dataset(test_path_nohomeo, trainset_output.sensor_size, trainset_output.classes, dtype=trainset_output.dtype, transform=type_transform)\n",
    "                test_outputloader_nohomeo = get_loader(testset_output_nohomeo, shuffle=False)\n",
    "                \n",
    "                print(len(test_outputloader), len(test_outputloader_nohomeo))\n",
    "                \n",
    "                likelihood, true_target, timestamps = predict_mlr(classif_layer,tau_cla,test_outputloader,results_path,ts_size, testset_output.ordering)\n",
    "                meanac, onlinac, lastac = score_classif_events(likelihood, true_target, n_classes, thres = mlr_threshold, verbose=False)\n",
    "\n",
    "                histo_score = make_histogram_classification(trainset_output, testset_output, n_output_neurons)\n",
    "                histo_score_nohomeo = make_histogram_classification(trainset_output_nohomeo, testset_output_nohomeo, n_output_neurons)\n",
    "                \n",
    "                print(f'Accuracy for jitter {jitter}:')\n",
    "                print(f'online HOTS -> {meanac*100} % - {lastac*100} %')\n",
    "                print(f'histogram score: {histo_score_nohomeo*100} % - homeo {histo_score*100} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8990223-8d4e-44ff-ba9e-924dd32bdf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_jitter = 2\n",
    "nb_trials = 10\n",
    "nb_points = 20\n",
    "\n",
    "filtering_threshold = [2*Rz[L] for L in range(len(Rz))]\n",
    "\n",
    "trainset_output_jitter = HOTS_Dataset(train_path, trainset.sensor_size, trainset.classes, dtype=trainset.dtype, transform=type_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888bc1b-972b-4420-816f-f430673c7e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "hots.name = initial_name\n",
    "hots_nohomeo.name = initial_name_nohomeo\n",
    "standard_spatial_jitter_min = 0\n",
    "standard_spatial_jitter_max = 10\n",
    "run_jitter(standard_spatial_jitter_min, standard_spatial_jitter_max, 'spatial', hots, hots_nohomeo, dataset_name, trainset_output_jitter, kfold = kfold_jitter, nb_trials = nb_trials, nb_points = nb_points, filtering_threshold = filtering_threshold, fitting = False);"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d844dcfb-8ed7-484a-8254-d95bb5a5f2fb",
   "metadata": {},
   "source": [
    "standard_spatial_jitter_min = 0\n",
    "standard_spatial_jitter_max = 10\n",
    "run_jitter(standard_spatial_jitter_min, standard_spatial_jitter_max, 'spatial', hots, hots_nohomeo, dataset_name, trainset_output_jitter, kfold = kfold_jitter, nb_trials = nb_trials, nb_points = nb_points, filtering_threshold = filtering_threshold, fitting = False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ccb161-5b0b-4d03-bb0e-4baa38e4f443",
   "metadata": {},
   "source": [
    "## Robustness to temporal jitter (Figure 5-(b)-(down))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb81605f-0301-4d62-b098-5c9e70c0d9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "hots.name = initial_name\n",
    "hots_nohomeo.name = initial_name_nohomeo\n",
    "standard_temporal_jitter_min = 3\n",
    "standard_temporal_jitter_max = 7\n",
    "run_jitter(standard_temporal_jitter_min, standard_temporal_jitter_max, 'temporal', hots, hots_nohomeo, dataset_name, trainset_output_jitter, kfold = kfold_jitter, nb_trials = nb_trials, nb_points = nb_points, filtering_threshold = filtering_threshold, fitting = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f132db-1fb2-4f56-8d1b-cbc806248b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
