{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "146e9eb1-7f15-4122-a866-cd3061b73da0",
   "metadata": {},
   "source": [
    "# RESULTS DVS Gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a75ff8-780a-400b-9925-515f4a2274cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6346880-ad3c-4a2c-a39a-1a8842c3ac3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/antoine/homhots/hotsline/hots\n",
      "Tonic version installed -> 1.0.19\n",
      "Number of GPU devices available: 1\n",
      "GPU 1 named GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "%cd ../hots\n",
    "import tonic, torch, os, pickle\n",
    "from tqdm import tqdm\n",
    "from network import network\n",
    "from layer import mlrlayer\n",
    "from timesurface import timesurface\n",
    "from utils import apply_jitter, get_loader, get_sliced_loader, make_histogram_classification, HOTS_Dataset, fit_mlr, predict_mlr, score_classif_events, plotjitter, printfig\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(f'Tonic version installed -> {tonic.__version__}')\n",
    "\n",
    "print(f'Number of GPU devices available: {torch.cuda.device_count()}')\n",
    "for N_gpu in range(torch.cuda.device_count()):\n",
    "    print(f'GPU {N_gpu+1} named {torch.cuda.get_device_name(N_gpu)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae45cc7-c96c-4c5f-8b9b-efa613afd9b3",
   "metadata": {},
   "source": [
    "## Loading of the dataset for the clustering phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe228881-0acd-422e-9376-966d47b0425b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Data/DVSGesture/metadata/gesture_1000_True_True\n",
      "Read metadata from disk.\n",
      "../../Data/DVSGesture/metadata/gesture_1000_True_True\n",
      "Read metadata from disk.\n",
      "../../Data/DVSGesture/metadata/gesture_1000_True_False\n",
      "Read metadata from disk.\n",
      "number of samples in the training set: 1077\n",
      "number of samples in the testing set: 264\n"
     ]
    }
   ],
   "source": [
    "kfold_test = None\n",
    "kfold_clust = 10\n",
    "ts_batch_size = 100\n",
    "\n",
    "dataset_name = 'gesture'\n",
    "slicing_time_window = 1e6\n",
    "\n",
    "type_transform = tonic.transforms.NumpyAsType(int)\n",
    "trainset = tonic.datasets.DVSGesture(save_to='../../Data/', train=True, transform=type_transform)\n",
    "testset = tonic.datasets.DVSGesture(save_to='../../Data/', train=False, transform=type_transform)\n",
    "loader = get_sliced_loader(trainset, slicing_time_window, dataset_name, True, only_first=True, kfold=kfold_clust)\n",
    "trainloader = get_sliced_loader(trainset, slicing_time_window, dataset_name, True, only_first=True, kfold=kfold_test)\n",
    "num_sample_train = len(trainloader)\n",
    "testloader = get_sliced_loader(testset, slicing_time_window, dataset_name, False, only_first=True, kfold=kfold_test)\n",
    "num_sample_test = len(testloader)\n",
    "n_classes = len(testset.classes)\n",
    "print(f'number of samples in the training set: {len(trainloader)}')\n",
    "print(f'number of samples in the testing set: {len(testloader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce771bc-ad2d-45c4-ba80-0a28862f07fe",
   "metadata": {},
   "source": [
    "## Initialization of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1caf366e-fc63-4030-868b-a57babe598de",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'homeohots'\n",
    "homeo = True\n",
    "timestr = '2022-04-22'\n",
    "dataset_name = 'gesture'\n",
    "\n",
    "Rz = [4, 8]\n",
    "N_neuronz = [16, 32]\n",
    "tauz = [5e4*2, 5e4*16]\n",
    "\n",
    "hots = network(name, dataset_name, timestr, trainset.sensor_size, nb_neurons = N_neuronz, tau = tauz, R = Rz, homeo = homeo)\n",
    "\n",
    "initial_name = hots.name\n",
    "\n",
    "name_nohomeo = 'hots'\n",
    "hots_nohomeo = network(name, dataset_name, timestr, trainset.sensor_size, nb_neurons = N_neuronz, tau = tauz, R = Rz, homeo = False)\n",
    "\n",
    "initial_name_nohomeo = hots_nohomeo.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804365ce-3c09-40a8-90ad-f2471961b169",
   "metadata": {},
   "source": [
    "## Unsupervised clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7064b789-7876-4611-8d34-3a5a4d62e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering_threshold = [2*Rz[L] for L in range(len(Rz))]\n",
    "if not os.path.exists('../Records/'):\n",
    "    os.mkdir('../Records/')\n",
    "    os.mkdir('../Records/networks/')\n",
    "path = '../Records/networks/'+hots.name+'.pkl'\n",
    "if not os.path.exists(path):\n",
    "    hots.clustering(loader, trainset.ordering, filtering_threshold = filtering_threshold)\n",
    "path_nohomeo = '../Records/networks/'+hots_nohomeo.name+'.pkl'\n",
    "if not os.path.exists(path_nohomeo):\n",
    "    hots_nohomeo.clustering(loader, trainset.ordering, filtering_threshold = filtering_threshold)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b4026f06-4803-47cb-9f6c-8857d32aa05b",
   "metadata": {},
   "source": [
    "hots.plotlayers();\n",
    "hots_nohomeo.plotlayers();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0361ae-8651-4ca6-95db-d3161988f90c",
   "metadata": {},
   "source": [
    "## Training of the classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ad1021c-e642-432f-a6a5-80aee959e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter = (None, None)\n",
    "\n",
    "hots.coding(trainloader, trainset.ordering, trainset.classes, filtering_threshold = filtering_threshold, training=True, verbose=False)\n",
    "hots.coding(testloader, trainset.ordering, trainset.classes, filtering_threshold = filtering_threshold, training=False, verbose=False)\n",
    "\n",
    "hots_nohomeo.coding(trainloader, trainset.ordering, trainset.classes, filtering_threshold = filtering_threshold, training=True, verbose=False)\n",
    "hots_nohomeo.coding(testloader, testset.ordering, testset.classes, filtering_threshold = filtering_threshold, training=False, jitter=jitter, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0a911b9-b781-4e79-a4f9-494dd90615ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "learning_rate = 0.0001\n",
    "beta1, beta2 = 0.9, 0.999\n",
    "betas = (beta1, beta2)\n",
    "num_epochs = 2 ** 5 + 1\n",
    "N_output_neurons = N_neuronz[-1]\n",
    "ts_size = (trainset.sensor_size[0],trainset.sensor_size[1],N_output_neurons)\n",
    "tau_cla = 5e5\n",
    "drop_proba = .9\n",
    "\n",
    "train_path = f'../Records/output/train/{hots.name}_{num_sample_train}_{jitter}/'\n",
    "test_path = f'../Records/output/test/{hots.name}_{num_sample_test}_{jitter}/'\n",
    "model_path = f'../Records/networks/{hots.name}_{tau_cla}_{learning_rate}_{betas}_{num_epochs}_{drop_proba}_{jitter}.pkl'\n",
    "results_path = f'../Records/LR_results/{hots.name}_{tau_cla}_{learning_rate}_{betas}_{num_epochs}_{drop_proba}_{jitter}.pkl'\n",
    "\n",
    "hots.coding(trainloader, trainset.ordering, trainset.classes, training=True, verbose=False)\n",
    "hots.coding(testloader, testset.ordering, testset.classes, training=False, verbose=False)\n",
    "\n",
    "drop_transform = tonic.transforms.DropEvent(p = drop_proba)\n",
    "\n",
    "trainset_output = HOTS_Dataset(train_path, trainset.sensor_size, trainset.classes, dtype=trainset.dtype, transform=tonic.transforms.Compose([drop_transform, type_transform]))\n",
    "trainoutputloader = get_loader(trainset_output)\n",
    "testset_output = HOTS_Dataset(test_path, testset.sensor_size, testset.classes, dtype=testset.dtype, transform=type_transform)\n",
    "testoutputloader = get_loader(testset_output)\n",
    "\n",
    "classif_layer, losses = fit_mlr(trainoutputloader, model_path, tau_cla, learning_rate, betas, num_epochs, ts_size, trainset.ordering, len(trainset.classes), ts_batch_size = ts_batch_size)\n",
    "\n",
    "hots_nohomeo.coding(trainloader, trainset.ordering, trainset.classes, training=True, verbose=False)\n",
    "\n",
    "train_path_nohomeo = f'../Records/output/train/{hots_nohomeo.name}_{num_sample_train}_{jitter}/'\n",
    "test_path_nohomeo = f'../Records/output/test/{hots_nohomeo.name}_{num_sample_test}_{jitter}/'\n",
    "\n",
    "trainset_output_nohomeo = HOTS_Dataset(train_path_nohomeo, trainset.sensor_size, trainset.classes, dtype=trainset.dtype, transform=type_transform)\n",
    "\n",
    "hots_nohomeo.coding(testloader, testset.ordering, testset.classes, training=False, jitter=jitter, verbose=False)\n",
    "testset_output_nohomeo = HOTS_Dataset(test_path_nohomeo, trainset.sensor_size, trainset.classes, dtype=trainset.dtype, transform=type_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af758dec-069d-4c2e-9576-f3c8005693db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_nohomeo = f'../Records/output/train/{hots_nohomeo.name}_{num_sample_train}_{jitter}/'\n",
    "test_path_nohomeo = f'../Records/output/test/{hots_nohomeo.name}_{num_sample_test}_{jitter}/'\n",
    "\n",
    "trainset_output_nohomeo = HOTS_Dataset(train_path_nohomeo, trainset.sensor_size, trainset.classes, dtype=trainset.dtype, transform=type_transform)\n",
    "\n",
    "hots_nohomeo.coding(testloader, testset.ordering, testset.classes, training=False, jitter=jitter, verbose=False)\n",
    "testset_output_nohomeo = HOTS_Dataset(test_path_nohomeo, trainset.sensor_size, trainset.classes, dtype=trainset.dtype, transform=type_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97301a0-bdce-4595-95f0-ae50fd56b372",
   "metadata": {},
   "source": [
    "## Online Inference (Figure 4-(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e385305b-1b7a-4f42-91bb-d308dd5521ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▌                                                                                                                                             | 1/264 [01:36<7:04:09, 96.77s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m likelihood, true_target, timestamps \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_mlr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassif_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtau_cla\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtestoutputloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mresults_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mts_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtestset_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mordering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mts_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mts_batch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m score \u001b[38;5;241m=\u001b[39m make_histogram_classification(trainset_output, testset_output, N_neuronz[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      3\u001b[0m score_nohomeo \u001b[38;5;241m=\u001b[39m make_histogram_classification(trainset_output_nohomeo, testset_output_nohomeo, N_neuronz[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/homhots/hotsline/hots/utils.py:395\u001b[0m, in \u001b[0;36mpredict_mlr\u001b[0;34m(mlrlayer, tau_cla, loader, results_path, timesurface_size, ordering, save, ts_batch_size)\u001b[0m\n\u001b[1;32m    393\u001b[0m outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor([])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m load_nb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nb_batch):\n\u001b[0;32m--> 395\u001b[0m     X, ind_filtered, previous_timestamp \u001b[38;5;241m=\u001b[39m \u001b[43mtimesurface\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimesurface_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimesurface_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimesurface_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mordering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtau_cla\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mts_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_number\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mload_nb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_timestamp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprevious_timestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m     n_events \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    397\u001b[0m     X, label \u001b[38;5;241m=\u001b[39m X, label\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/homhots/hotsline/hots/timesurface.py:66\u001b[0m, in \u001b[0;36mtimesurface\u001b[0;34m(events, sensor_size, ordering, surface_dimensions, tau, decay, filtering_threshold, ts_batch_size, load_number, previous_timestamp, device, dtype)\u001b[0m\n\u001b[1;32m     64\u001b[0m         timesurface \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(timestamp_context \u001b[38;5;241m/\u001b[39m tau)\n\u001b[1;32m     65\u001b[0m         timesurface[timesurface\u001b[38;5;241m<\u001b[39mtorch\u001b[38;5;241m.\u001b[39mexp(torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m))] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 66\u001b[0m     all_surfaces[index, :, :, :] \u001b[38;5;241m=\u001b[39m timesurface\n\u001b[1;32m     67\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filtering_threshold:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "likelihood, true_target, timestamps = predict_mlr(classif_layer,tau_cla,testoutputloader,results_path,ts_size,testset_output.ordering,  ts_batch_size = ts_batch_size)\n",
    "score = make_histogram_classification(trainset_output, testset_output, N_neuronz[-1])\n",
    "score_nohomeo = make_histogram_classification(trainset_output_nohomeo, testset_output_nohomeo, N_neuronz[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bdb7b3f-05ca-4ba3-a863-49ac0f578ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7613636363636364 0.6297029702970297\n"
     ]
    }
   ],
   "source": [
    "print(score, score_nohomeo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5549ad4b-36a4-44bc-88ee-692495809bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chance decisions: 0\n",
      "90th quantile for number of events: 123356.50000000007\n",
      "Mean accuracy: 14.799999999999999%\n",
      "Last accuracy: 18.2%\n",
      "Highest probability accuracy: 18.2%\n"
     ]
    }
   ],
   "source": [
    "mlr_threshold = None\n",
    "meanac, onlinac, lastac, best_probability = score_classif_events(likelihood, true_target, n_classes, thres = mlr_threshold, original_accuracy = score, original_accuracy_nohomeo = score_nohomeo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33777f05-8ecb-4503-ba89-23258a9db097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chance decisions: 234\n",
      "90th quantile for number of events: 123356.50000000007\n",
      "Mean accuracy: 11.200000000000001%\n",
      "Last accuracy: 16.3%\n",
      "Highest probability accuracy: 18.2%\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m mlr_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.99\u001b[39m\n\u001b[0;32m----> 3\u001b[0m meanac, onlinac, lastac \u001b[38;5;241m=\u001b[39m score_classif_events(likelihood, true_target, n_classes, thres \u001b[38;5;241m=\u001b[39m mlr_threshold, original_accuracy \u001b[38;5;241m=\u001b[39m score, original_accuracy_nohomeo \u001b[38;5;241m=\u001b[39m score_nohomeo)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "mlr_threshold = .99\n",
    "meanac, onlinac, lastac = score_classif_events(likelihood, true_target, n_classes, thres = mlr_threshold, original_accuracy = score, original_accuracy_nohomeo = score_nohomeo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75378b6a-ba60-4813-afb9-cf7405f24043",
   "metadata": {},
   "source": [
    "## Robustness to spatial jitter (Figure 5-(b)-(up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5ca5fe-2166-43d0-b965-87fe53bd7d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def run_jitter(min_jitter, max_jitter, jitter_type, hots, hots_nohomeo, dataset_name, trainset_output, filtering_threshold = None, kfold = None, nb_trials = 10, nb_points = 20, fitting = True, figure_name = None, verbose = False):\n",
    "    \n",
    "    initial_name = copy.copy(hots.name)\n",
    "    initial_name_nohomeo = copy.copy(hots_nohomeo.name)\n",
    "    \n",
    "    n_classes = len(trainset_output.classes)\n",
    "    n_output_neurons = len(hots.layers[-1].cumhisto)\n",
    "    ts_size = [trainset_output.sensor_size[0],trainset_output.sensor_size[1],n_output_neurons]\n",
    "    \n",
    "    ts_batch_size = None\n",
    "    mlr_threshold = .99\n",
    "    type_transform = tonic.transforms.NumpyAsType(int)\n",
    "    \n",
    "    if not os.path.exists('../Records/jitter_results/'):\n",
    "        os.mkdir('../Records/jitter_results/')\n",
    "    if jitter_type=='temporal':\n",
    "        std_jit_t = np.logspace(min_jitter,max_jitter,nb_points)\n",
    "        jitter_values = std_jit_t\n",
    "    else:\n",
    "        std_jit_s = np.linspace(min_jitter,max_jitter,nb_points)\n",
    "        var_jit_s = std_jit_s**2\n",
    "        jitter_values = var_jit_s\n",
    "\n",
    "    jitter_path = f'../Records/jitter_results/{initial_name}_{nb_trials}_{min_jitter}_{max_jitter}_{kfold}_{nb_points}'\n",
    "\n",
    "    if not os.path.exists(jitter_path+'.npz'):\n",
    "\n",
    "        torch.set_default_tensor_type(\"torch.DoubleTensor\")\n",
    "\n",
    "        for trial in tqdm(range(nb_trials)):\n",
    "            for ind_jit, jitter_val in enumerate(jitter_values):\n",
    "                if jitter_val==0:\n",
    "                    jitter = (None,None)\n",
    "                else:\n",
    "                    if jitter_type=='temporal':\n",
    "                        jitter = (None,jitter_val)\n",
    "                    else:\n",
    "                        jitter = (jitter_val,None)\n",
    "                        \n",
    "                hots.name = initial_name+f'_{trial}'\n",
    "                hots_nohomeo.name = initial_name_nohomeo+f'_{trial}'\n",
    "                \n",
    "                drop_proba = .5\n",
    "\n",
    "                if jitter_type=='temporal':\n",
    "                    temporal_jitter_transform = tonic.transforms.TimeJitter(std = jitter_val, clip_negative = True, sort_timestamps = True)\n",
    "                    transform_full = tonic.transforms.Compose([temporal_jitter_transform, type_transform])\n",
    "                    if drop_proba:\n",
    "                        drop_transform = tonic.transforms.DropEvent(p = drop_proba)\n",
    "                        transform_full = tonic.transforms.Compose([drop_transform, temporal_jitter_transform, type_transform])\n",
    "                else:\n",
    "                    spatial_jitter_transform = tonic.transforms.SpatialJitter(sensor_size = trainset_output.sensor_size, variance_x = jitter_val, variance_y = jitter_val, clip_outliers = True)\n",
    "                    transform_full = tonic.transforms.Compose([spatial_jitter_transform, type_transform])\n",
    "                    if drop_proba:\n",
    "                        drop_transform = tonic.transforms.DropEvent(p = drop_proba)\n",
    "                        transform_full = tonic.transforms.Compose([drop_transform, spatial_jitter_transform, type_transform])\n",
    "                    \n",
    "                if dataset_name=='poker':\n",
    "                    testset = tonic.datasets.POKERDVS(save_to='../../Data/', train=False, transform=transform_full)\n",
    "                    testloader = get_loader(testset, kfold = kfold)\n",
    "                elif dataset_name=='nmnist':\n",
    "                    testset = tonic.datasets.NMNIST(save_to='../../Data/', train=False, transform=transform_full)\n",
    "                    testloader = get_loader(testset, kfold = kfold)\n",
    "                elif dataset_name=='gesture':\n",
    "                    testset = tonic.datasets.DVSGesture(save_to='../../Data/', train=False, transform=transform_full)\n",
    "                    testloader = get_sliced_loader(testset, slicing_time_window, dataset_name, False, only_first=True, kfold=kfold)\n",
    "                    \n",
    "                num_sample_test = len(testloader)\n",
    "                test_path = f'../Records/output/test/{hots.name}_{num_sample_test}_{jitter}/'\n",
    "                test_path_nohomeo = f'../Records/output/test/{hots_nohomeo.name}_{num_sample_test}_{jitter}/'\n",
    "                    \n",
    "                print(test_path)\n",
    "                \n",
    "                hots.coding(testloader, trainset_output.ordering, testset.classes, training=False, jitter = jitter, filtering_threshold = filtering_threshold, ts_batch_size = ts_batch_size, verbose=False)\n",
    "                hots_nohomeo.coding(testloader, trainset_output.ordering, testset.classes, training=False, jitter=jitter, filtering_threshold=filtering_threshold, ts_batch_size = ts_batch_size, verbose=False)\n",
    "                \n",
    "                testset_output = HOTS_Dataset(test_path, trainset_output.sensor_size, trainset_output.classes, dtype=trainset_output.dtype, transform=type_transform)\n",
    "                test_outputloader = get_loader(testset_output, shuffle=False)\n",
    "                \n",
    "                testset_output_nohomeo = HOTS_Dataset(test_path_nohomeo, trainset_output.sensor_size, trainset_output.classes, dtype=trainset_output.dtype, transform=type_transform)\n",
    "                test_outputloader_nohomeo = get_loader(testset_output_nohomeo, shuffle=False)\n",
    "                \n",
    "                print(len(test_outputloader), len(test_outputloader_nohomeo))\n",
    "                \n",
    "                likelihood, true_target, timestamps = predict_mlr(classif_layer,tau_cla,test_outputloader,results_path,ts_size, testset_output.ordering)\n",
    "                meanac, onlinac, lastac = score_classif_events(likelihood, true_target, n_classes, thres = mlr_threshold, verbose=False)\n",
    "\n",
    "                histo_score = make_histogram_classification(trainset_output, testset_output, n_output_neurons)\n",
    "                histo_score_nohomeo = make_histogram_classification(trainset_output_nohomeo, testset_output_nohomeo, n_output_neurons)\n",
    "                \n",
    "                print(f'Accuracy for jitter {jitter}:')\n",
    "                print(f'online HOTS -> {meanac*100} % - {lastac*100} %')\n",
    "                print(f'histogram score: {histo_score_nohomeo*100} % - homeo {histo_score*100} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8990223-8d4e-44ff-ba9e-924dd32bdf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_jitter = 2\n",
    "nb_trials = 10\n",
    "nb_points = 10\n",
    "\n",
    "filtering_threshold = [2*Rz[L] for L in range(len(Rz))]\n",
    "\n",
    "trainset_output_jitter = HOTS_Dataset(train_path, trainset.sensor_size, trainset.classes, dtype=trainset.dtype, transform=type_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888bc1b-972b-4420-816f-f430673c7e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "hots.name = initial_name\n",
    "hots_nohomeo.name = initial_name_nohomeo\n",
    "standard_spatial_jitter_min = 0\n",
    "standard_spatial_jitter_max = 10\n",
    "run_jitter(standard_spatial_jitter_min, standard_spatial_jitter_max, 'spatial', hots, hots_nohomeo, dataset_name, trainset_output_jitter, kfold = kfold_jitter, nb_trials = nb_trials, nb_points = nb_points, filtering_threshold = filtering_threshold, fitting = False);"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d844dcfb-8ed7-484a-8254-d95bb5a5f2fb",
   "metadata": {},
   "source": [
    "standard_spatial_jitter_min = 0\n",
    "standard_spatial_jitter_max = 10\n",
    "run_jitter(standard_spatial_jitter_min, standard_spatial_jitter_max, 'spatial', hots, hots_nohomeo, dataset_name, trainset_output_jitter, kfold = kfold_jitter, nb_trials = nb_trials, nb_points = nb_points, filtering_threshold = filtering_threshold, fitting = False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ccb161-5b0b-4d03-bb0e-4baa38e4f443",
   "metadata": {},
   "source": [
    "## Robustness to temporal jitter (Figure 5-(b)-(down))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb81605f-0301-4d62-b098-5c9e70c0d9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "hots.name = initial_name\n",
    "hots_nohomeo.name = initial_name_nohomeo\n",
    "standard_temporal_jitter_min = 3\n",
    "standard_temporal_jitter_max = 7\n",
    "run_jitter(standard_temporal_jitter_min, standard_temporal_jitter_max, 'temporal', hots, hots_nohomeo, dataset_name, trainset_output_jitter, kfold = kfold_jitter, nb_trials = nb_trials, nb_points = nb_points, filtering_threshold = filtering_threshold, fitting = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f132db-1fb2-4f56-8d1b-cbc806248b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
