{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "146e9eb1-7f15-4122-a866-cd3061b73da0",
   "metadata": {},
   "source": [
    "# RESULTS DVS Gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a75ff8-780a-400b-9925-515f4a2274cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6346880-ad3c-4a2c-a39a-1a8842c3ac3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/INT/grimaldi.a/Documents/projets/HOTS/hotsline/hots\n",
      "Tonic version installed -> 1.0.19\n",
      "Number of GPU devices available: 1\n",
      "GPU 1 named Quadro RTX 5000\n"
     ]
    }
   ],
   "source": [
    "%cd ../hots\n",
    "import tonic, torch, os, pickle\n",
    "from tqdm import tqdm\n",
    "from network import network\n",
    "from layer import mlrlayer\n",
    "from timesurface import timesurface\n",
    "from utils import apply_jitter, get_loader, get_sliced_loader, make_histogram_classification, HOTS_Dataset, fit_mlr, predict_mlr, score_classif_events, plotjitter, printfig, online_accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(f'Tonic version installed -> {tonic.__version__}')\n",
    "\n",
    "print(f'Number of GPU devices available: {torch.cuda.device_count()}')\n",
    "for N_gpu in range(torch.cuda.device_count()):\n",
    "    print(f'GPU {N_gpu+1} named {torch.cuda.get_device_name(N_gpu)}')\n",
    "    \n",
    "record_path = '/envau/work/neopto/USERS/GRIMALDI/HOTS/hotsline/Records/'\n",
    "record_path = '../Records/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae45cc7-c96c-4c5f-8b9b-efa613afd9b3",
   "metadata": {},
   "source": [
    "## Loading of the dataset for the clustering phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe228881-0acd-422e-9376-966d47b0425b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Data/DVSGesture/metadata/gesture_1000_True_True\n",
      "Read metadata from disk.\n",
      "../../Data/DVSGesture/metadata/gesture_1000_True_True\n",
      "Read metadata from disk.\n",
      "../../Data/DVSGesture/metadata/gesture_1000_True_False\n",
      "Read metadata from disk.\n",
      "number of samples in the training set: 1077\n",
      "number of samples in the testing set: 264\n"
     ]
    }
   ],
   "source": [
    "kfold_test = None\n",
    "kfold_clust = 10\n",
    "ts_batch_size = 1000\n",
    "\n",
    "dataset_name = 'gesture'\n",
    "slicing_time_window = 1e6\n",
    "\n",
    "type_transform = tonic.transforms.NumpyAsType(int)\n",
    "trainset = tonic.datasets.DVSGesture(save_to='../../Data/', train=True, transform=type_transform)\n",
    "testset = tonic.datasets.DVSGesture(save_to='../../Data/', train=False, transform=type_transform)\n",
    "loader = get_sliced_loader(trainset, slicing_time_window, dataset_name, True, only_first=True, kfold=kfold_clust)\n",
    "trainloader = get_sliced_loader(trainset, slicing_time_window, dataset_name, True, only_first=True, kfold=kfold_test)\n",
    "num_sample_train = len(trainloader)\n",
    "testloader = get_sliced_loader(testset, slicing_time_window, dataset_name, False, only_first=True, kfold=kfold_test)\n",
    "num_sample_test = len(testloader)\n",
    "n_classes = len(testset.classes)\n",
    "print(f'number of samples in the training set: {len(trainloader)}')\n",
    "print(f'number of samples in the testing set: {len(testloader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce771bc-ad2d-45c4-ba80-0a28862f07fe",
   "metadata": {},
   "source": [
    "## Initialization of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1caf366e-fc63-4030-868b-a57babe598de",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'homeohots'\n",
    "homeo = True\n",
    "#timestr = '2022-04-22'\n",
    "timestr = '2022-10-12'\n",
    "dataset_name = 'gesture'\n",
    "\n",
    "Rz = [4, 8]\n",
    "N_neuronz = [16, 32]\n",
    "#tauz = [5e4*2, 5e4*16]\n",
    "tauz = [3e3*2, 3e3*16]\n",
    "\n",
    "hots = network(name, dataset_name, timestr, trainset.sensor_size, nb_neurons = N_neuronz, tau = tauz, R = Rz, homeo = homeo, record_path=record_path)\n",
    "\n",
    "initial_name = hots.name\n",
    "\n",
    "name_nohomeo = 'hots'\n",
    "hots_nohomeo = network(name, dataset_name, timestr, trainset.sensor_size, nb_neurons = N_neuronz, tau = tauz, R = Rz, homeo = False, record_path=record_path)\n",
    "\n",
    "initial_name_nohomeo = hots_nohomeo.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804365ce-3c09-40a8-90ad-f2471961b169",
   "metadata": {},
   "source": [
    "##Â Unsupervised clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7064b789-7876-4611-8d34-3a5a4d62e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering_threshold = [2*Rz[L] for L in range(len(Rz))]\n",
    "if not os.path.exists(record_path):\n",
    "    os.mkdir(record_path)\n",
    "    os.mkdir(record_path+'networks/')\n",
    "path = record_path+'networks/'+hots.name+'.pkl'\n",
    "if not os.path.exists(path):\n",
    "    hots.clustering(loader, trainset.ordering, filtering_threshold = filtering_threshold)\n",
    "path_nohomeo = record_path+'networks/'+hots_nohomeo.name+'.pkl'\n",
    "if not os.path.exists(path_nohomeo):\n",
    "    hots_nohomeo.clustering(loader, trainset.ordering, filtering_threshold = filtering_threshold)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87aa0652-0aaa-484a-8427-c7bb24c72016",
   "metadata": {},
   "source": [
    "hots.plotlayers();\n",
    "hots_nohomeo.plotlayers();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0361ae-8651-4ca6-95db-d3161988f90c",
   "metadata": {},
   "source": [
    "## Training of the classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ad1021c-e642-432f-a6a5-80aee959e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter = (None, None)\n",
    "\n",
    "hots.coding(trainloader, trainset.ordering, trainset.classes, filtering_threshold = filtering_threshold, training=True, verbose=False)\n",
    "hots.coding(testloader, trainset.ordering, trainset.classes, filtering_threshold = filtering_threshold, training=False, verbose=False)\n",
    "\n",
    "hots_nohomeo.coding(trainloader, trainset.ordering, trainset.classes, filtering_threshold = filtering_threshold, training=True, verbose=False)\n",
    "hots_nohomeo.coding(testloader, testset.ordering, testset.classes, filtering_threshold = filtering_threshold, training=False, jitter=jitter, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0a911b9-b781-4e79-a4f9-494dd90615ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Records/networks/2022-10-12_gesture_homeohots_True_[16, 32]_[6000.0, 48000.0]_[4, 8]_96000.0_0.0001_(0.9, 0.999)_65_0.9_(None, None).pkl\n"
     ]
    }
   ],
   "source": [
    "num_workers = 0\n",
    "learning_rate = 0.0001\n",
    "beta1, beta2 = 0.9, 0.999\n",
    "betas = (beta1, beta2)\n",
    "num_epochs = 2 ** 6 + 1\n",
    "N_output_neurons = N_neuronz[-1]\n",
    "ts_size = (trainset.sensor_size[0],trainset.sensor_size[1],N_output_neurons)\n",
    "tau_cla = 3e3*32\n",
    "drop_proba = .9\n",
    "\n",
    "train_path = f'../Records/output/train/{hots.name}_{num_sample_train}_{jitter}/'\n",
    "test_path = f'../Records/output/test/{hots.name}_{num_sample_test}_{jitter}/'\n",
    "model_path = f'../Records/networks/{hots.name}_{tau_cla}_{learning_rate}_{betas}_{num_epochs}_{drop_proba}_{jitter}.pkl'\n",
    "results_path = f'../Records/LR_results/{hots.name}_{tau_cla}_{learning_rate}_{betas}_{num_epochs}_{drop_proba}_{jitter}.pkl'\n",
    "print(model_path)\n",
    "\n",
    "drop_transform = tonic.transforms.DropEvent(p = drop_proba)\n",
    "kfold_mlr = None\n",
    "\n",
    "trainset_output = HOTS_Dataset(train_path, trainset.sensor_size, trainset.classes, dtype=trainset.dtype, transform=tonic.transforms.Compose([drop_transform, type_transform]))\n",
    "trainoutputloader = get_loader(trainset_output, kfold = kfold_mlr)\n",
    "testset_output = HOTS_Dataset(test_path, testset.sensor_size, testset.classes, dtype=testset.dtype, transform=type_transform)\n",
    "testoutputloader = get_loader(testset_output)\n",
    "\n",
    "classif_layer, losses = fit_mlr(trainoutputloader, model_path, tau_cla, learning_rate, betas, num_epochs, ts_size, trainset.ordering, len(trainset.classes), ts_batch_size = ts_batch_size)\n",
    "\n",
    "train_path_nohomeo = f'../Records/output/train/{hots_nohomeo.name}_{num_sample_train}_{jitter}/'\n",
    "test_path_nohomeo = f'../Records/output/test/{hots_nohomeo.name}_{num_sample_test}_{jitter}/'\n",
    "\n",
    "trainset_output_nohomeo = HOTS_Dataset(train_path_nohomeo, trainset.sensor_size, trainset.classes, dtype=trainset.dtype, transform=type_transform)\n",
    "testset_output_nohomeo = HOTS_Dataset(test_path_nohomeo, trainset.sensor_size, trainset.classes, dtype=trainset.dtype, transform=type_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d106a0a-22bc-4355-bd1a-8d38d0c9138b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2384199160>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4964def5-4565-4a54-8ff8-770c3629e0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n",
      "../Records/networks/2022-10-12_gesture_homeohots_True_[16, 32]_[6000.0, 48000.0]_[4, 8]_9600.0_0.0001_(0.9, 0.999)_33_0.95_(None, None).pkl\n",
      "device -> cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                         | 0/33 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_775928/2504442117.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmlr_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mclassif_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_mlr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainoutputloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau_cla\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mordering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0monlinac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_probability\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeanac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlastac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monline_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassif_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau_cla\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestoutputloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestset_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mordering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlr_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlr_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#likelihood, true_target, timestamps = predict_mlr(classif_layer,tau_cla,testoutputloader,results_path,ts_size,testset_output.ordering,  ts_batch_size = ts_batch_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projets/HOTS/hotsline/hots/utils.py\u001b[0m in \u001b[0;36mfit_mlr\u001b[0;34m(loader, model_path, tau_cla, learning_rate, betas, num_epochs, ts_size, ordering, n_classes, ts_batch_size, drop_proba, device)\u001b[0m\n\u001b[1;32m    312\u001b[0m                     \u001b[0mprevious_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mload_nb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m                         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind_filtered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimesurface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mts_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtau_cla\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrop_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_nb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                         \u001b[0mn_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projets/HOTS/hotsline/hots/timesurface.py\u001b[0m in \u001b[0;36mtimesurface\u001b[0;34m(events, sensor_size, ordering, surface_dimensions, tau, decay, filtering_threshold, drop_proba, ts_batch_size, load_number, previous_timestamp, device, dtype)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mtimestamp_memory\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         all_surfaces = torch.zeros(\n\u001b[0m\u001b[1;32m     34\u001b[0m             (ts_batch_size, sensor_size[2], surface_dimensions[1],surface_dimensions[0])).to(device)\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload_number\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mnb_full_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tau_cla_list = [3e2*32, 3e3*32, 3e4*32, 3e5*32, 3e6*32, 3e7*32]\n",
    "num_epochs = 33\n",
    "device = 'cuda'\n",
    "drop_proba = .95\n",
    "kfold_mlr = 4\n",
    "trainoutputloader = get_loader(trainset_output, kfold = kfold_mlr)\n",
    "print(len(trainoutputloader))\n",
    "\n",
    "for tau_cla in tau_cla_list:\n",
    "\n",
    "    model_path = f'../Records/networks/{hots.name}_{tau_cla}_{learning_rate}_{betas}_{num_epochs}_{drop_proba}_{jitter}.pkl'\n",
    "    results_path = f'../Records/LR_results/{hots.name}_{tau_cla}_{learning_rate}_{betas}_{num_epochs}_{drop_proba}_{jitter}.pkl'\n",
    "    print(model_path)\n",
    "    mlr_threshold = None\n",
    "    classif_layer, losses = fit_mlr(trainoutputloader, model_path, tau_cla, learning_rate, betas, num_epochs, ts_size, trainset.ordering, len(trainset.classes), ts_batch_size = ts_batch_size, device = device)\n",
    "    onlinac, best_probability, meanac, lastac = online_accuracy(classif_layer, tau_cla, testoutputloader, results_path, ts_size, testset_output.ordering, n_classes, mlr_threshold = mlr_threshold, ts_batch_size = ts_batch_size)\n",
    "    #likelihood, true_target, timestamps = predict_mlr(classif_layer,tau_cla,testoutputloader,results_path,ts_size,testset_output.ordering,  ts_batch_size = ts_batch_size)\n",
    "    #meanac, onlinac, lastac, best_probac = score_classif_events(likelihood, true_target, n_classes, original_accuracy = score, original_accuracy_nohomeo = score_nohomeo)#, figure_name = 'nmnist_online.pdf')\n",
    "    print(f'For tau = {tau_cla} last accuracy: {lastac*100}% - mean accuracy: {meanac*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97301a0-bdce-4595-95f0-ae50fd56b372",
   "metadata": {},
   "source": [
    "## Online Inference (Figure 4-(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13ef3cc-d3fa-4834-a41d-880273894407",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = make_histogram_classification(trainset_output, testset_output, N_neuronz[-1])\n",
    "score_nohomeo = make_histogram_classification(trainset_output_nohomeo, testset_output_nohomeo, N_neuronz[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f837711-f0b5-46c5-8771-b67944bf607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score, score_nohomeo)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87d7a918-9d41-43c2-9f44-f2c8d3cf2214",
   "metadata": {},
   "source": [
    "score = 0.727\n",
    "score_nohomeo = 0.712"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5549ad4b-36a4-44bc-88ee-692495809bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_threshold = None\n",
    "onlinac = online_accuracy(classif_layer, tau_cla, testoutputloader, results_path, ts_size, testset_output.ordering, n_classes, mlr_threshold = mlr_threshold, ts_batch_size = ts_batch_size, original_accuracy = score, original_accuracy_nohomeo = score_nohomeo, online_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33777f05-8ecb-4503-ba89-23258a9db097",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_threshold = .99\n",
    "onlinac_thres = online_accuracy(classif_layer, tau_cla, testoutputloader, results_path, ts_size, testset_output.ordering, n_classes, mlr_threshold = mlr_threshold, ts_batch_size = ts_batch_size, original_accuracy = score, original_accuracy_nohomeo = score_nohomeo, online_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcfcbb1-48ad-4223-8496-dec33c8d5842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "event_90th = 106517\n",
    "sampling = (np.logspace(0,np.log10(event_90th),100)).astype(int)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.semilogx(sampling[:-1],onlinac[0][sampling[:-1]]*100, '.', label='online HOTS (ours)');\n",
    "ax.semilogx(sampling[:-1],onlinac_thres[0][sampling[:-1]]*100, '.', label='online HOTS \\nwith threshold', alpha = .5);\n",
    "ax.hlines(1/n_classes*100,0,event_90th, linestyles='dashed', color='k', label='chance level')\n",
    "ax.hlines(score_nohomeo*100,0,event_90th, linestyles='dashed', color='r', label='original HOTS')\n",
    "ax.hlines(score*100,0,event_90th, linestyles='dashed', color='g', label='HOTS with homeostasis')\n",
    "ax.set_xlabel('Number of events', fontsize=16);\n",
    "ax.axis([1,event_90th,0,101]);\n",
    "#plt.title('LR classification results evolution as a function of the number of events');\n",
    "plt.setp(ax.get_xticklabels(),fontsize=12)\n",
    "#ax.set_yticks([])\n",
    "plt.setp(ax.get_yticklabels(),fontsize=12)\n",
    "#ax.set_ylabel('Accuracy (in %)', fontsize=16);\n",
    "#ax.legend(fontsize=10, loc='upper left');\n",
    "    #printfig(fig, figure_name)\n",
    "ax.set_yticklabels(['']*5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad74d78b-b717-40d8-a566-2bb02754c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'gesture_online.pdf'\n",
    "\n",
    "dpi_exp = None\n",
    "bbox = 'tight'\n",
    "path = '../../manuscript/fig/'\n",
    "#path = '../../GrimaldiEtAl2020HOTS_clone_laurent/fig'\n",
    "fig.savefig(path+name, dpi = dpi_exp, bbox_inches=bbox, transparent=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d969d5d-5f3c-41dd-8c6d-21afd31daa1b",
   "metadata": {},
   "source": [
    "kernels = classif_layer.linear.weight.data.cpu().numpy()\n",
    "fig, ax = plt.subplots(N_output_neurons, kernels.shape[0], figsize=(30, 90))\n",
    "for n in range(kernels.shape[0]):\n",
    "    kernel = kernels[n].reshape(trainset.sensor_size[0],trainset.sensor_size[1], N_output_neurons)\n",
    "    for p in range(N_output_neurons):\n",
    "        ax[p, n].imshow(kernel[:,:,p])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75378b6a-ba60-4813-afb9-cf7405f24043",
   "metadata": {},
   "source": [
    "## Robustness to spatial jitter (Figure 5-(b)-(up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5ca5fe-2166-43d0-b965-87fe53bd7d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def run_jitter(min_jitter, max_jitter, jitter_type, hots, hots_nohomeo, dataset_name, trainset_output, filtering_threshold = None, kfold = None, nb_trials = 10, nb_points = 20, fitting = True, figure_name = None, verbose = False):\n",
    "    \n",
    "    initial_name = copy.copy(hots.name)\n",
    "    initial_name_nohomeo = copy.copy(hots_nohomeo.name)\n",
    "    \n",
    "    n_classes = len(trainset_output.classes)\n",
    "    n_output_neurons = len(hots.layers[-1].cumhisto)\n",
    "    ts_size = [trainset_output.sensor_size[0],trainset_output.sensor_size[1],n_output_neurons]\n",
    "    \n",
    "    ts_batch_size = None\n",
    "    mlr_threshold = .99\n",
    "    type_transform = tonic.transforms.NumpyAsType(int)\n",
    "    \n",
    "    if not os.path.exists('../Records/jitter_results/'):\n",
    "        os.mkdir('../Records/jitter_results/')\n",
    "    if jitter_type=='temporal':\n",
    "        std_jit_t = np.logspace(min_jitter,max_jitter,nb_points)\n",
    "        jitter_values = std_jit_t\n",
    "    else:\n",
    "        std_jit_s = np.linspace(min_jitter,max_jitter,nb_points)\n",
    "        var_jit_s = std_jit_s**2\n",
    "        jitter_values = var_jit_s\n",
    "\n",
    "    jitter_path = f'../Records/jitter_results/{initial_name}_{nb_trials}_{min_jitter}_{max_jitter}_{kfold}_{nb_points}'\n",
    "\n",
    "    if not os.path.exists(jitter_path+'.npz'):\n",
    "\n",
    "        torch.set_default_tensor_type(\"torch.DoubleTensor\")\n",
    "\n",
    "        for trial in tqdm(range(nb_trials)):\n",
    "            for ind_jit, jitter_val in enumerate(jitter_values):\n",
    "                if jitter_val==0:\n",
    "                    jitter = (None,None)\n",
    "                else:\n",
    "                    if jitter_type=='temporal':\n",
    "                        jitter = (None,jitter_val)\n",
    "                    else:\n",
    "                        jitter = (jitter_val,None)\n",
    "                        \n",
    "                hots.name = initial_name+f'_{trial}'\n",
    "                hots_nohomeo.name = initial_name_nohomeo+f'_{trial}'\n",
    "                \n",
    "                drop_proba = .5\n",
    "\n",
    "                if jitter_type=='temporal':\n",
    "                    temporal_jitter_transform = tonic.transforms.TimeJitter(std = jitter_val, clip_negative = True, sort_timestamps = True)\n",
    "                    transform_full = tonic.transforms.Compose([temporal_jitter_transform, type_transform])\n",
    "                    if drop_proba:\n",
    "                        drop_transform = tonic.transforms.DropEvent(p = drop_proba)\n",
    "                        transform_full = tonic.transforms.Compose([drop_transform, temporal_jitter_transform, type_transform])\n",
    "                else:\n",
    "                    spatial_jitter_transform = tonic.transforms.SpatialJitter(sensor_size = trainset_output.sensor_size, variance_x = jitter_val, variance_y = jitter_val, clip_outliers = True)\n",
    "                    transform_full = tonic.transforms.Compose([spatial_jitter_transform, type_transform])\n",
    "                    if drop_proba:\n",
    "                        drop_transform = tonic.transforms.DropEvent(p = drop_proba)\n",
    "                        transform_full = tonic.transforms.Compose([drop_transform, spatial_jitter_transform, type_transform])\n",
    "                    \n",
    "                if dataset_name=='poker':\n",
    "                    testset = tonic.datasets.POKERDVS(save_to='../../Data/', train=False, transform=transform_full)\n",
    "                    testloader = get_loader(testset, kfold = kfold)\n",
    "                elif dataset_name=='nmnist':\n",
    "                    testset = tonic.datasets.NMNIST(save_to='../../Data/', train=False, transform=transform_full)\n",
    "                    testloader = get_loader(testset, kfold = kfold)\n",
    "                elif dataset_name=='gesture':\n",
    "                    testset = tonic.datasets.DVSGesture(save_to='../../Data/', train=False, transform=transform_full)\n",
    "                    testloader = get_sliced_loader(testset, slicing_time_window, dataset_name, False, only_first=True, kfold=kfold)\n",
    "                    \n",
    "                num_sample_test = len(testloader)\n",
    "                test_path = f'../Records/output/test/{hots.name}_{num_sample_test}_{jitter}/'\n",
    "                test_path_nohomeo = f'../Records/output/test/{hots_nohomeo.name}_{num_sample_test}_{jitter}/'\n",
    "                    \n",
    "                print(test_path)\n",
    "                \n",
    "                hots.coding(testloader, trainset_output.ordering, testset.classes, training=False, jitter = jitter, filtering_threshold = filtering_threshold, ts_batch_size = ts_batch_size, verbose=False)\n",
    "                hots_nohomeo.coding(testloader, trainset_output.ordering, testset.classes, training=False, jitter=jitter, filtering_threshold=filtering_threshold, ts_batch_size = ts_batch_size, verbose=False)\n",
    "                \n",
    "                testset_output = HOTS_Dataset(test_path, trainset_output.sensor_size, trainset_output.classes, dtype=trainset_output.dtype, transform=type_transform)\n",
    "                test_outputloader = get_loader(testset_output, shuffle=False)\n",
    "                \n",
    "                testset_output_nohomeo = HOTS_Dataset(test_path_nohomeo, trainset_output.sensor_size, trainset_output.classes, dtype=trainset_output.dtype, transform=type_transform)\n",
    "                test_outputloader_nohomeo = get_loader(testset_output_nohomeo, shuffle=False)\n",
    "                \n",
    "                print(len(test_outputloader), len(test_outputloader_nohomeo))\n",
    "                \n",
    "                likelihood, true_target, timestamps = predict_mlr(classif_layer,tau_cla,test_outputloader,results_path,ts_size, testset_output.ordering)\n",
    "                meanac, onlinac, lastac = score_classif_events(likelihood, true_target, n_classes, thres = mlr_threshold, verbose=False)\n",
    "\n",
    "                histo_score = make_histogram_classification(trainset_output, testset_output, n_output_neurons)\n",
    "                histo_score_nohomeo = make_histogram_classification(trainset_output_nohomeo, testset_output_nohomeo, n_output_neurons)\n",
    "                \n",
    "                print(f'Accuracy for jitter {jitter}:')\n",
    "                print(f'online HOTS -> {meanac*100} % - {lastac*100} %')\n",
    "                print(f'histogram score: {histo_score_nohomeo*100} % - homeo {histo_score*100} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8990223-8d4e-44ff-ba9e-924dd32bdf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_jitter = 2\n",
    "nb_trials = 10\n",
    "nb_points = 20\n",
    "\n",
    "filtering_threshold = [2*Rz[L] for L in range(len(Rz))]\n",
    "\n",
    "trainset_output_jitter = HOTS_Dataset(train_path, trainset.sensor_size, trainset.classes, dtype=trainset.dtype, transform=type_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888bc1b-972b-4420-816f-f430673c7e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "hots.name = initial_name\n",
    "hots_nohomeo.name = initial_name_nohomeo\n",
    "standard_spatial_jitter_min = 0\n",
    "standard_spatial_jitter_max = 10\n",
    "run_jitter(standard_spatial_jitter_min, standard_spatial_jitter_max, 'spatial', hots, hots_nohomeo, dataset_name, trainset_output_jitter, kfold = kfold_jitter, nb_trials = nb_trials, nb_points = nb_points, filtering_threshold = filtering_threshold, fitting = False);"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d844dcfb-8ed7-484a-8254-d95bb5a5f2fb",
   "metadata": {},
   "source": [
    "standard_spatial_jitter_min = 0\n",
    "standard_spatial_jitter_max = 10\n",
    "run_jitter(standard_spatial_jitter_min, standard_spatial_jitter_max, 'spatial', hots, hots_nohomeo, dataset_name, trainset_output_jitter, kfold = kfold_jitter, nb_trials = nb_trials, nb_points = nb_points, filtering_threshold = filtering_threshold, fitting = False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ccb161-5b0b-4d03-bb0e-4baa38e4f443",
   "metadata": {},
   "source": [
    "## Robustness to temporal jitter (Figure 5-(b)-(down))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb81605f-0301-4d62-b098-5c9e70c0d9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "hots.name = initial_name\n",
    "hots_nohomeo.name = initial_name_nohomeo\n",
    "standard_temporal_jitter_min = 3\n",
    "standard_temporal_jitter_max = 7\n",
    "run_jitter(standard_temporal_jitter_min, standard_temporal_jitter_max, 'temporal', hots, hots_nohomeo, dataset_name, trainset_output_jitter, kfold = kfold_jitter, nb_trials = nb_trials, nb_points = nb_points, filtering_threshold = filtering_threshold, fitting = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f132db-1fb2-4f56-8d1b-cbc806248b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1, 2, 3, 4])\n",
    "p = torch.tensor([0.1, 0.1, 0.1, 0.7])\n",
    "n = 3\n",
    "replace = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8dad78-8c75-431f-b303-9d6d24c97db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = p.multinomial(num_samples=n, replacement=replace)\n",
    "b = a[idx]\n",
    "print(idx, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156cddcf-e897-41f1-8286-631c751d33ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.uniform_(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729d84a3-2a5e-4da5-b75f-eadad2fd7c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d1c629-78c0-4116-8088-ac8aabced316",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[[1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f20a0b-7510-47d2-ba14-63d832ee7f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_random, _ = torch.randperm(200)[:10].sort()\n",
    "print(indices_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9922754f-5833-4611-9b37-dff6fbffb52c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
