{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "146e9eb1-7f15-4122-a866-cd3061b73da0",
   "metadata": {},
   "source": [
    "# BASICS 02 - HOTS in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a75ff8-780a-400b-9925-515f4a2274cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6346880-ad3c-4a2c-a39a-1a8842c3ac3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/antoine/homhots/hotsline/hots\n",
      "Tonic version installed -> 1.0.15\n",
      "Number of GPU devices available: 1\n",
      "GPU 1 named GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "%cd ../hots\n",
    "import tonic, torch, os, pickle\n",
    "from tqdm import tqdm\n",
    "from network import network\n",
    "from layer import mlrlayer\n",
    "from timesurface import timesurface\n",
    "from utils import get_loader, make_histogram_classification, HOTS_Dataset\n",
    "\n",
    "print(f'Tonic version installed -> {tonic.__version__}')\n",
    "\n",
    "print(f'Number of GPU devices available: {torch.cuda.device_count()}')\n",
    "for N_gpu in range(torch.cuda.device_count()):\n",
    "    print(f'GPU {N_gpu+1} named {torch.cuda.get_device_name(N_gpu)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae45cc7-c96c-4c5f-8b9b-efa613afd9b3",
   "metadata": {},
   "source": [
    "## Loading of the dataset for the clustering phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe228881-0acd-422e-9376-966d47b0425b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples in the training set: 48\n"
     ]
    }
   ],
   "source": [
    "transform = tonic.transforms.NumpyAsType(int)\n",
    "trainset = tonic.datasets.POKERDVS(save_to='../../Data/', train=True, transform=transform)\n",
    "testset = tonic.datasets.POKERDVS(save_to='../../Data/', train=False, transform=transform)\n",
    "loader = get_loader(trainset)\n",
    "num_sample_train = len(loader)\n",
    "num_sample_test = len(testset)\n",
    "print(f'number of samples in the training set: {len(loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce771bc-ad2d-45c4-ba80-0a28862f07fe",
   "metadata": {},
   "source": [
    "## Initialization of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1caf366e-fc63-4030-868b-a57babe598de",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'homeohots'\n",
    "homeo = True\n",
    "timestr = '2022-04-22'\n",
    "dataset_name = 'poker'\n",
    "\n",
    "Rz = [2, 4]\n",
    "N_neuronz = [4, 8]\n",
    "tauz = [1e3, 2e3]\n",
    "\n",
    "hots = network(name, dataset_name, timestr, trainset.sensor_size, nb_neurons = N_neuronz, tau = tauz, R = Rz, homeo = homeo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804365ce-3c09-40a8-90ad-f2471961b169",
   "metadata": {},
   "source": [
    "##Â Unsupervised clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7064b789-7876-4611-8d34-3a5a4d62e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../Records/'):\n",
    "    os.mkdir('../Records/')\n",
    "    os.mkdir('../Records/networks/')\n",
    "filtering_threshold = [2*Rz[L] for L in range(len(Rz))]\n",
    "path = '../Records/networks/'+hots.name+'.pkl'\n",
    "if not os.path.exists(path):\n",
    "    hots.clustering(loader, trainset.ordering, filtering_threshold, record = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0361ae-8651-4ca6-95db-d3161988f90c",
   "metadata": {},
   "source": [
    "## Training of the classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0a911b9-b781-4e79-a4f9-494dd90615ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter = (None, None)\n",
    "\n",
    "train_path = f'../Records/output/train/{hots.name}_{num_sample_train}_{jitter}/'\n",
    "test_path = f'../Records/output/test/{hots.name}_{num_sample_test}_{jitter}/'\n",
    "\n",
    "tau_cla = 1e4\n",
    "\n",
    "transform = tonic.transforms.Compose([tonic.transforms.ToTimesurface(sensor_size=trainset.sensor_size, tau=tau_cla, decay=\"exp\")])\n",
    "\n",
    "transform = tonic.transforms.NumpyAsType(int)\n",
    "testset_output = HOTS_Dataset(test_path, trainset.sensor_size, dtype=trainset.dtype, transform=transform)\n",
    "trainset_output = HOTS_Dataset(train_path, trainset.sensor_size, dtype=trainset.dtype, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d97501cc-b28d-4467-9776-6a90b56e6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_mlr(loader, \n",
    "            model_path,\n",
    "            tau_cla,\n",
    "            learning_rate,\n",
    "            betas,\n",
    "            num_epochs,\n",
    "            ts_size,\n",
    "            ordering,\n",
    "            n_classes,\n",
    "            num_workers=0):\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        with open(model_path, 'rb') as file:\n",
    "            classif_layer, losses = pickle.load(file)\n",
    "    \n",
    "    else:\n",
    "        torch.set_default_tensor_type(\"torch.DoubleTensor\")\n",
    "        criterion = torch.nn.BCELoss(reduction=\"mean\")\n",
    "        amsgrad = True #or False gives similar results\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        N = ts_size[0]*ts_size[1]*ts_size[2]\n",
    "\n",
    "        classif_layer = mlrlayer(N, n_classes, device=device)\n",
    "        classif_layer.train()\n",
    "        optimizer = torch.optim.Adam(\n",
    "            classif_layer.parameters(), lr=learning_rate, betas=betas, amsgrad=amsgrad\n",
    "        )\n",
    "\n",
    "        for epoch in tqdm(range(int(num_epochs))):\n",
    "            losses = []\n",
    "            for events, label in loader:\n",
    "                X, ind_filtered = timesurface(events.squeeze(0).squeeze(0), (ts_size[0], ts_size[1], ts_size[2]), ordering, tau = tau_cla, device=device)\n",
    "                \n",
    "                X, label = X.to(device) ,label.to(device)\n",
    "                X = X.reshape(X.shape[0], N)\n",
    "\n",
    "                outputs = classif_layer(X)\n",
    "\n",
    "                n_events = X.shape[0]\n",
    "                labels = label*torch.ones(n_events).type(torch.LongTensor).to(device)\n",
    "                labels = torch.nn.functional.one_hot(labels, num_classes=n_classes).type(torch.DoubleTensor).to(device)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                losses.append(loss.item())\n",
    "\n",
    "        with open(model_path, 'wb') as file:\n",
    "            pickle.dump([classif_layer, losses], file, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        return classif_layer, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c389f98e-2832-42af-8fdd-4b9a241dd956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                   | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "loader = get_loader(trainset_output)\n",
    "model_path = 'test.pkl'\n",
    "\n",
    "num_workers = 0\n",
    "learning_rate = 0.005\n",
    "beta1, beta2 = 0.9, 0.999\n",
    "betas = (beta1, beta2)\n",
    "num_epochs = 3 #2 ** 5 + 1\n",
    "ts_size = (trainset.sensor_size[0],trainset.sensor_size[1],N_neuronz[-1])\n",
    "\n",
    "classif_layer, losses = fit_mlr(loader, model_path, tau_cla, learning_rate, betas, num_epochs, ts_size, trainset.ordering, len(trainset.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e4def6-afc7-4f1e-b8a7-786004b955ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
