{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1323e1fd-cd1d-4b6f-8de6-0a71f2d7a0b8",
   "metadata": {},
   "source": [
    "# [hotsline](https://github.com/AntoineGrimaldi/hotsline) algorithm to replicate results from [this paper](https://www.techrxiv.org/articles/preprint/A_robust_event-driven_approach_to_always-on_object_recognition/18003077/1)\n",
    "## Load events of the N-MNIST dataset with [Tonic](https://tonic.readthedocs.io/en/latest/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41e167bc-5794-4989-8b83-eb671436db30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tonic version installed -> 1.0.15\n",
      "number of samples in the dataset: 200\n"
     ]
    }
   ],
   "source": [
    "import tonic\n",
    "from utils import get_loader\n",
    "\n",
    "print(f' Tonic version installed -> {tonic.__version__}')\n",
    "\n",
    "transform = tonic.transforms.NumpyAsType(int)\n",
    "dataset = tonic.datasets.NMNIST(save_to='../../Data/', train=True, transform=transform)\n",
    "loader = get_loader(dataset, kfold = 300, shuffle=True)\n",
    "#get_dataset_info(dataset, properties = ['time', 'mean_isi', 'nb_events']);\n",
    "print(f'number of samples in the dataset: {len(loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "931d892b-d49f-4aed-8bb0-0d6cd09db3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/antoine/homhots/hotsline/hots\n"
     ]
    }
   ],
   "source": [
    "%cd ../hots\n",
    "from layer import hotslayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb9e26a-7985-4fa8-9587-57c13793d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = (2, 4, 8)\n",
    "n_neurons = (4, 8, 16)\n",
    "n_pola = 2\n",
    "ts_size1 = (2*R[0]+1)**2*n_pola\n",
    "tau = (5e3, 5e4, 5e5)#7e2\n",
    "ts_size2 = (2*R[1]+1)**2*n_neurons[0]\n",
    "ts_size3 = (2*R[2]+1)**2*n_neurons[1]\n",
    "verbose = True\n",
    "\n",
    "p_index = dataset.ordering.index('p')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if verbose: print(f'device -> {device}')\n",
    "\n",
    "torch.set_default_tensor_type(\"torch.DoubleTensor\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_pola = []\n",
    "    layer1 = hotslayer(ts_size1, n_neurons[0], device=device)\n",
    "    #layer1.learning_flag = False\n",
    "    #layer1.to(device)\n",
    "    layer2 = hotslayer(ts_size2, n_neurons[1], device=device)\n",
    "    #layer2.learning_flag = False\n",
    "    #layer2.to(device)\n",
    "    layer3 = hotslayer(ts_size3, n_neurons[2], device=device)\n",
    "    #layer3.learning_flag = False\n",
    "    #layer3.to(device)\n",
    "    for events, target in tqdm(loader):\n",
    "        all_ts, ind_filtered = timesurface(events.squeeze(0), dataset.sensor_size, dataset.ordering, tau = tau[0], surface_dimensions=[2*R[0]+1,2*R[0]+1], filtering_threshold = 2*R[0], device=device)\n",
    "        layer1.to(device)\n",
    "        n_star = layer1(all_ts.to(device).squeeze(0))\n",
    "        layer1.to('cpu')\n",
    "        if ind_filtered is not None:\n",
    "            events = events[:,ind_filtered,:]\n",
    "        events[0,:,p_index] = n_star.cpu()\n",
    "        sensor_size = [dataset.sensor_size[0], dataset.sensor_size[1], n_neurons[0]]\n",
    "        del all_ts\n",
    "        torch.cuda.empty_cache()\n",
    "        all_ts, ind_filtered = timesurface(events.squeeze(0), sensor_size, dataset.ordering, tau = tau[1], surface_dimensions=[2*R[1]+1,2*R[1]+1], filtering_threshold = 2*R[1], device=device)\n",
    "        layer2.to(device)\n",
    "        n_star = layer2(all_ts.to(device).squeeze(0))\n",
    "        layer2.to('cpu')\n",
    "        sensor_size = [dataset.sensor_size[0], dataset.sensor_size[1], n_neurons[1]]\n",
    "        if ind_filtered is not None:\n",
    "            events = events[:,ind_filtered,:]\n",
    "        events[0,:,p_index] = n_star.cpu()\n",
    "        del all_ts\n",
    "        torch.cuda.empty_cache()\n",
    "        all_ts, ind_filtered = timesurface(events.squeeze(0), sensor_size, dataset.ordering, tau = tau[2], surface_dimensions=[2*R[2]+1,2*R[2]+1], filtering_threshold = 2*R[2], device=device)\n",
    "        layer3.to(device)\n",
    "        n_star = layer3(all_ts.to(device).squeeze(0))\n",
    "        layer3.to('cpu')\n",
    "        if ind_filtered is not None:\n",
    "            events = events[:,ind_filtered,:]\n",
    "        events[0,:,p_index] = n_star.cpu()\n",
    "        output_pola.append(n_star.cpu())\n",
    "        del all_ts\n",
    "        torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
