{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d292319-2b71-4351-adb5-2b7724a1cad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tonic, torch, os\n",
    "from hots.network import network\n",
    "from hots.utils import apply_jitter, get_loader, get_sliced_loader, make_histogram_classification, HOTS_Dataset, fit_mlr, predict_mlr, score_classif_events\n",
    "import numpy as np\n",
    "\n",
    "print(f'Tonic version installed -> {tonic.__version__}')\n",
    "\n",
    "print(f'Number of GPU devices available: {torch.cuda.device_count()}')\n",
    "for N_gpu in range(torch.cuda.device_count()):\n",
    "    print(f'GPU {N_gpu+1} named {torch.cuda.get_device_name(N_gpu)}')\n",
    "    \n",
    "    \n",
    "kfold_test = 2\n",
    "kfold_clust = 10\n",
    "\n",
    "dataset_name = 'gesture'\n",
    "slicing_time_window = 1e6\n",
    "\n",
    "type_transform = tonic.transforms.NumpyAsType(int)\n",
    "trainset = tonic.datasets.DVSGesture(save_to='../../Data/', train=True, transform=type_transform)\n",
    "testset = tonic.datasets.DVSGesture(save_to='../../Data/', train=False, transform=type_transform)\n",
    "loader = get_sliced_loader(trainset, slicing_time_window, dataset_name, True, only_first=True, kfold=kfold_clust)\n",
    "trainloader = get_sliced_loader(trainset, slicing_time_window, dataset_name, True, only_first=True, kfold=kfold_test)\n",
    "num_sample_train = len(trainloader)\n",
    "testloader = get_sliced_loader(testset, slicing_time_window, dataset_name, False, only_first=True, kfold=kfold_test)\n",
    "num_sample_test = len(testloader)\n",
    "n_classes = len(testset.classes)\n",
    "print(f'number of samples in the training set: {len(trainloader)}')\n",
    "print(f'number of samples in the testing set: {len(testloader)}')\n",
    "\n",
    "name = 'homeohots'\n",
    "homeo = True\n",
    "timestr = '2022-04-22'\n",
    "\n",
    "Rz = [4, 8]\n",
    "N_neuronz = [16, 32]\n",
    "tauz = [5e4*2, 5e4*16]\n",
    "\n",
    "hots = network(name, dataset_name, timestr, trainset.sensor_size, nb_neurons = N_neuronz, tau = tauz, R = Rz, homeo = homeo)\n",
    "\n",
    "#initial_name = hots.name\n",
    "\n",
    "filtering_threshold = [2*Rz[L] for L in range(len(Rz))]\n",
    "if not os.path.exists('../Records/'):\n",
    "    os.mkdir('../Records/')\n",
    "    os.mkdir('../Records/networks/')\n",
    "path = '../Records/networks/'+hots.name+'.pkl'\n",
    "if not os.path.exists(path):\n",
    "    hots.clustering(loader, trainset.ordering, filtering_threshold = filtering_threshold)\n",
    "    \n",
    "jitter = (None, None)\n",
    "num_workers = 0\n",
    "learning_rate = 0.005\n",
    "beta1, beta2 = 0.9, 0.999\n",
    "betas = (beta1, beta2)\n",
    "num_epochs = 8 #2 ** 5 + 1\n",
    "N_output_neurons = N_neuronz[-1]\n",
    "ts_size = (trainset.sensor_size[0],trainset.sensor_size[1],N_output_neurons)\n",
    "tau_cla_list = [1e5, 2e5, 3e5, 5e5, 1e6, 2e6]\n",
    "\n",
    "train_path = f'../Records/output/train/{hots.name}_{num_sample_train}_{jitter}/'\n",
    "test_path = f'../Records/output/test/{hots.name}_{num_sample_test}_{jitter}/'\n",
    "\n",
    "hots.coding(trainloader, trainset.ordering, trainset.classes, training=True, verbose=False)\n",
    "hots.coding(testloader, testset.ordering, testset.classes, training=False, verbose=False)\n",
    "\n",
    "trainset_output = HOTS_Dataset(train_path, trainset.sensor_size, trainset.classes, dtype=trainset.dtype, transform=type_transform)\n",
    "trainoutputloader = get_loader(trainset_output)\n",
    "testset_output = HOTS_Dataset(test_path, testset.sensor_size, testset.classes, dtype=testset.dtype, transform=type_transform)\n",
    "testoutputloader = get_loader(testset_output)\n",
    "\n",
    "for tau_cla in tau_cla_list:\n",
    "    \n",
    "    model_path = f'../Records/networks/{hots.name}_{tau_cla}_{learning_rate}_{betas}_{num_epochs}_{jitter}.pkl'\n",
    "    results_path = f'../Records/LR_results/{hots.name}_{tau_cla}_{learning_rate}_{betas}_{num_epochs}_{jitter}.pkl'\n",
    "    \n",
    "    classif_layer, losses = fit_mlr(trainoutputloader, model_path, tau_cla, learning_rate, betas, num_epochs, ts_size, trainset.ordering, len(trainset.classes), multiple_ts_load = 6)\n",
    "    likelihood, true_target, timestamps = predict_mlr(classif_layer,tau_cla,testoutputloader,results_path,ts_size,testset_output.ordering)\n",
    "    meanac, onlinac, lastac = score_classif_events(likelihood, true_target, n_classes, original_accuracy = score, original_accuracy_nohomeo = score_nohomeo, figure_name = 'nmnist_online.pdf')\n",
    "    print(f'For tau = {tau} last accuracy: {lastac*100}% - mean accuracy: {meanac*100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
